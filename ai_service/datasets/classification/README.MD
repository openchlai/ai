---
dataset_info:
  features:
  - name: uniqueid
    dtype: decimal128(14, 4)
  - name: transcription
    dtype: string
  - name: translation
    dtype: string
  - name: startdate
    dtype: string
  - name: starttime
    dtype: string
  - name: stoptime
    dtype: string
  - name: talktime
    dtype: string
  - name: category
    dtype: string
  - name: category_definition
    dtype: string
  - name: victim
    dtype: string
  - name: reporter
    dtype: string
  - name: county
    dtype: string
  - name: subcounty
    dtype: string
  - name: ward
    dtype: string
  - name: landmark
    dtype: string
  - name: perpetrator
    dtype: string
  - name: counselor
    dtype: string
  - name: narrative
    dtype: string
  - name: intervention
    dtype: string
  - name: priority
    dtype: int64
  splits:
  - name: train
    num_bytes: 33902801
    num_examples: 13167
  download_size: 14716708
  dataset_size: 33902801
configs:
- config_name: default
  data_files:
  - split: train
    path: data/train-*
license: apache-2.0
task_categories:
- text-classification
language:
- en
tags:
- helpline
- openchs
- distilbert
size_categories:
- 10K<n<100K
---

# Synthetic Helpline Call Classification Dataset

Synthetic conversation data for training and evaluating child helpline case classification and quality assessment models in East African contexts.

## Dataset Details

### Dataset Description

This is a **fully synthetic dataset** of helpline conversations generated for training multitask classification models for the OpenCHS AI Pipeline. The dataset simulates realistic child helpline scenarios across various case categories, maintaining the structure and complexity of real helpline data while ensuring complete privacy and ethical compliance.

All conversations, names, locations, and identifying information are **entirely fictional** and generated using advanced language models with careful prompt engineering to reflect authentic East African helpline contexts, linguistic patterns, and case types.

**Key characteristics:**
- **Fully synthetic**: No real calls or personal information
- **Diverse case types**: Covers major categories including abuse, neglect, HIV/AIDS, homelessness, drug/alcohol issues
- **Realistic dialogue**: Natural conversation flows between callers and helpline agents
- **Hierarchical labels**: Multiple classification targets (category, priority, intervention)
- **Cultural context**: Reflects East African names, locations, and social contexts


- **Generated by:** OpenCHS AI Pipeline Team, BITZ IT Consulting
- **Language(s) (NLP):** English
- **License:** 

### Dataset Sources

- **Repository:** https://huggingface.co/datasets/openchs/synthetic_helpine_classification_v1
- **Generation Method:** LLM-based synthesis with human validation
- **Project:** OpenCHS AI Pipeline

## Uses

### Direct Use

This synthetic dataset is ideal for:

1. **Model Training**: Train classification models without privacy concerns
2. **Algorithm Development**: Test new architectures and approaches safely
3. **Benchmarking**: Establish baseline performance metrics
4. **Educational Use**: Teaching NLP and social AI applications
5. **Prototyping**: Rapid experimentation before accessing real data
6. **Augmentation**: Supplement real data to address class imbalance
7. **Public Sharing**: Openly share methods and results without privacy restrictions

**Advantages of synthetic data:**
- No privacy risks or ethical concerns
- Can generate balanced classes
- Easy to scale and augment
- Public sharing and collaboration
- Safe for academic research and competitions

### Out-of-Scope Use

**Important limitations:**

- **512 Token Limit Exceeded**
- **Not for production deployment**: Synthetic data may not capture all real-world complexity
- **Distribution shift**: Real helpline calls may differ from synthetic patterns
- **Cultural nuance**: Generated content may miss subtle cultural contexts
- **Edge cases**: Rare but critical scenarios may be underrepresented
- **Must validate on real data**: Models trained on synthetic data require real-world testing

**This synthetic data should be used:**
- For initial model development and experimentation
- As augmentation to real data, not replacement
- With validation on real helpline data before deployment
- Understanding the gap between synthetic and authentic conversations

## Dataset Structure

### Data Fields

| Field | Type | Description |
|-------|------|-------------|
| `uniqueid` | float | Unique identifier for the call record |
| `transcription` | dict | Placeholder for audio transcription (empty in current version) |
| `translation` | dict | Placeholder for translation data (empty in current version) |
| `startdate` | string | Call start date (DD MMM YYYY format) |
| `starttime` | string | Call start time (HH:MM:SS format) |
| `stoptime` | string | Call end time (HH:MM:SS format) |
| `talktime` | string | Duration of call (MM:SS format) |
| `category` | string | Main case category |
| `category_definition` | string | Definition of the category |
| `victim` | dict | Nested JSON with victim information (gender, name, phone, age, birthday) |
| `reporter` | dict | Nested JSON with reporter information (gender, name, phone, age, relationship) |
| `county` | string | County location (Kenya administrative divisions) |
| `subcounty` | string | Subcounty location |
| `ward` | string | Ward location (lowest administrative unit) |
| `landmark` | string | Local landmark reference |
| `perpetrator` | dict | Nested JSON with perpetrator information (gender, name, phone, age, relationship) |
| `counselor` | string | Counselor identifier (anonymized) |
| `narrative` | string | Full conversation narrative between caller and helpline agent |
| `intervention` | string | Type of intervention provided (Counselling, Referral, etc.) |
| `priority` | float | Priority level (1.0=highest, 2.0=medium, 3.0=low) |

### Example Instance

```json
{
  "uniqueid": 1696525048.1374,
  "transcription": "{}",
  "translation": "{}",
  "startdate": "05 Oct 2023",
  "starttime": "19:57:28",
  "stoptime": "20:11:57",
  "talktime": "14:29",
  "category": "Drug/Alcohol Abuse",
  "category_definition": "The harmful or hazardous use of psychoactive substances...",
  "victim": {
    "gender": "female",
    "first_name": "Eunice",
    "last_name": "Akinyi",
    "phone_number": "0708674326",
    "age": "5",
    "birthday": "2018"
  },
  "reporter": {
    "gender": "female",
    "first_name": "Rose",
    "last_name": "Wakesho",
    "phone_number": "0190369901",
    "age": "Adult (25-40)",
    "relationship": "Parent"
  },
  "narrative": "Rose Wakesho (Caller): Hello, I need help...",
  "intervention": "Counselling",
  "priority": 2.0
}
```

### Nested JSON Fields

**Victim, Reporter, and Perpetrator fields** contain structured information:
- `gender`: "male", "female", or "unknown"
- `first_name`: Fictional East African first name
- `last_name`: Fictional East African surname
- `phone_number`: Fictional phone number or "Unknown"
- `age`: Age value or range (e.g., "5", "Adult (25-40)", "Middle-aged (41-60)")
- `birthday`: Year of birth (YYYY format) for children
- `relationship`: Relationship to victim (e.g., "Parent", "Relative", "Step-parent")

## Dataset Creation

### Curation Rationale

**Why synthetic data?**

1. **Privacy Protection**: Enables public sharing and collaboration without exposing sensitive real cases
2. **Ethical Compliance**: Avoids risks associated with anonymizing real crisis calls
3. **Rapid Prototyping**: Allows model development before accessing sensitive real data
4. **Data Augmentation**: Addresses class imbalance in real helpline datasets
5. **Educational Access**: Provides realistic case studies for training and education
6. **Benchmarking**: Creates standardized evaluation sets for algorithm comparison

### Source Data

#### Data Generation Process

**Generation Pipeline:**

1. **Scenario Design**: 
   - Defined case categories based on real helpline taxonomies
   - Specified demographic distributions and relationship patterns
   - Created realistic location names from Kenyan counties, subcounties, and wards

2. **LLM-Based Generation**:
   - Used advanced language models (GPT-4, Mistral) to generate conversation narratives
   - Prompt engineering to ensure cultural authenticity and linguistic patterns
   - Specified East African names, contexts, and communication styles

3. **Structured Data Addition**:
   - Generated victim/reporter/perpetrator metadata
   - Assigned priority levels based on case severity
   - Added intervention types aligned with case needs
   - Created temporal metadata (dates, times, call duration)

4. **Quality Control**:
   - Human review by helpline domain experts
   - Validation of cultural appropriateness
   - Checking for harmful stereotypes or biases
   - Ensuring conversational realism

5. **Diversity Enhancement**:
   - Varied case complexities and outcomes
   - Diverse age ranges, genders, and relationships
   - Multiple intervention types and priorities
   - Geographic diversity across Kenyan regions

**Generation Prompts Included:**
- Empathetic counselor responses
- Caller emotional states and concerns
- Realistic problem descriptions
- Appropriate intervention recommendations
- Natural conversation flow and turn-taking

#### Who are the source data producers?

**Generation Team:**
- NLP Engineers: Rogendo and OpenCHS technical team
- Domain Experts: Helpline counselors and case managers (validation)
- Cultural Consultants: East African professionals ensuring authenticity
- Language Specialists: Ensuring appropriate multilingual elements

**Quality Assurance:**
- Review by licensed counselors for realism
- Cultural sensitivity checks
- Removal of harmful stereotypes
- Validation of intervention appropriateness

### Annotations

All labels (category, priority, intervention) were assigned during the generation process based on the content of synthesized narratives. Label assignment follows standard helpline protocols and case management frameworks used in East African child protection services.

**Annotation principles:**
- Priority based on case urgency and risk level
- Categories aligned with child protection taxonomies
- Interventions matched to case needs
- Consistent with real helpline decision-making

### Personal and Sensitive Information

**This is entirely synthetic data.**

All names, phone numbers, locations, and case details are **completely fictional**. No real individuals, cases, or identifying information are present in this dataset.

**Synthetic generation ensures:**
- Zero privacy risk
- No re-identification possible
- No ethical concerns about consent
- Safe for public sharing and collaboration
- Appropriate for educational and research use

**Cultural sensitivity maintained:**
- Authentic East African names and contexts
- Respectful portrayal of sensitive issues
- Avoidance of harmful stereotypes
- Realistic but compassionate narratives

## Bias, Risks, and Limitations

### Synthetic Data Limitations

1. **Distribution Mismatch**:
   - Synthetic conversations may differ from real helpline call patterns
   - Models may not generalize perfectly to authentic data
   - Edge cases and rare scenarios may be underrepresented
   - Emotional nuance and linguistic complexity may be simplified

2. **Cultural Authenticity**:
   - Generated content reflects researcher understanding of context
   - May miss subtle cultural nuances and local knowledge
   - Code-switching patterns may not perfectly match real usage
   - Idiomatic expressions and colloquialisms may differ

3. **Scenario Bias**:
   - Generation prompts influence case distributions
   - May over-represent certain case types or patterns
   - Conversation structures may be more formulaic than real calls
   - Resolution patterns may differ from actual helpline outcomes

4. **Training Data Bias**:
   - LLMs used for generation have their own biases
   - Western perspectives may influence case framing
   - Language patterns reflect LLM training distributions
   - Generation models' knowledge cutoffs may affect context

### Risks

1. **Over-reliance on Synthetic Data**:
   - Models trained only on synthetic data may fail in production
   - Must validate on real data before deployment
   - Cannot replace real-world testing and evaluation

2. **False Confidence**:
   - Good performance on synthetic data doesn't guarantee real-world success
   - May mask critical failure modes present in authentic calls
   - Distribution shift between synthetic and real data

3. **Perpetuating Biases**:
   - If generation process contains biases, models will learn them
   - May reinforce stereotypes about demographics or case types
   - Requires careful bias auditing even for synthetic data

### Recommendations

**For Model Development:**

1. **Hybrid Approach**:
   - Use synthetic data for initial prototyping and architecture development
   - Validate on real helpline data before deployment
   - Use synthetic data to augment real data, not replace it
   - Test domain adaptation techniques to bridge synthetic-real gap

2. **Distribution Awareness**:
   - Although normaized and leveled distribution in this syntheetic set, we reecommend analyzing differences between synthetic and real data distributions
   - Use domain adaptation or transfer learning techniques
   - Monitor performance degradation on real data
   - Implement robustness checks for distribution shift

3. **Bias Mitigation**:
   - Audit synthetic data for demographic biases
   - Ensure diverse representation across scenarios
   - Test model fairness even on synthetic data
   - Validate that learned patterns transfer appropriately

**For Researchers:**

1. **Transparent Reporting**:
   - Clearly indicate when results are on synthetic vs. real data
   - Report performance gaps between synthetic and real evaluation
   - Describe generation process and potential limitations
   - Share synthetic data openly to enable reproducibility

2. **Responsible Use**:
   - Don't overstate findings from synthetic-only experiments
   - Acknowledge limitations of synthetic data
   - Require real-world validation before deployment claims
   - Consider synthetic data as one tool in the research toolkit

**Users should be aware that:**
- This is entirely synthetic data, not real helpline calls
- Models trained on this data require validation on authentic data
- Synthetic data is valuable for prototyping but has limitations
- Cultural and linguistic authenticity efforts were made but may not be perfect

## Citation

**BibTeX:**

```bibtex
@dataset{openchs_synthetic_helpline_2025,
  title={Synthetic East African Helpline Call Dataset},
  author={{OpenCHS AI Pipeline Team}},
  organization={BITZ IT Consulting},
  year={2025},
  publisher={Hugging Face},
  howpublished={\url{https://huggingface.co/datasets/openchs/synthetic_helpine_classification_v1}},
  note={Fully synthetic data for helpline case classification model development}
}
```

**APA:**

OpenCHS AI Pipeline Team. (2025). *Synthetic East African Helpline Call Dataset* [Dataset]. BITZ IT Consulting. https://huggingface.co/datasets/openchs/synthetic_helpine_classification_v1

## Glossary

**Synthetic Data**: Artificially generated data that mimics real-world patterns without containing actual observations

**LLM (Large Language Model)**: AI models like GPT-4 or Claude used to generate realistic text

**Code-switching**: Alternating between languages within a single conversation (common in East African multilingual contexts)

**Case Categories**: Classification of helpline cases (e.g., abuse, neglect, homelessness, HIV/AIDS, drug/alcohol issues)

**Intervention Types**: Actions taken by helpline (e.g., Counselling, Referral, Emergency Response)

**Priority Levels**: Urgency classification (1.0=highest, 2.0=medium, 3.0=low)

## More Information

### Related Datasets

- **Real OpenCHS Case Classification Dataset**: Anonymized real helpline data (restricted access)
- **Multilingual Transcription Dataset**: ASR training data for East African languages

### Future Work

- Generate larger volumes to match real data scale
- Enhance multilingual code-switching patterns
- Include audio synthesis for multimodal training
- Generate adversarial and edge cases for robustness testing
- Create cross-lingual variants (more Swahili-dominant conversations)

### Validation Studies

Models trained on this synthetic data should be validated against:
- Real helpline case classification accuracy
- Counselor feedback on prediction quality
- Live deployment performance monitoring
- Comparison with models trained on real data

## Dataset Card Authors

**Primary Author:** Rogendo (Data Engineering Lead, OpenCHS AI Pipeline)  
**Organization:** BITZ IT Consulting  
**Contributors:** OpenCHS AI Pipeline Team, Domain Expert Validators

## Dataset Card Contact

**Technical Contact:** [Add contact information]  
**Organization:** BITZ IT Consulting  
**Project:** OpenCHS AI Pipeline

---

*This synthetic dataset enables safe, ethical model development for improving crisis response services. All content is entirely fictional and generated for research purposes.*