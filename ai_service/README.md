# AI Pipeline Container - Multi-Modal Audio Processing System

[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.116.1-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?logo=docker&logoColor=white)](https://www.docker.com/)
[![Celery](https://img.shields.io/badge/celery-5.5.3-37b24d.svg)](https://docs.celeryproject.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Integration Status](https://img.shields.io/badge/integration-complete-brightgreen.svg)](#integration-status)

A production-ready, containerized AI pipeline for processing audio recordings into structured insights. Built for child protection organizations and social services to transform call recordings into actionable case analysis.

## Integration Status

### Unified End-to-End Service

This system provides a fully integrated AI pipeline combining **speech-to-text transcription**, **multilingual translation**, and **case prediction triage** into a single unified service. The pipeline processes voice and text inputs seamlessly through all stages, producing:

- **Transcription outputs** from audio input via Whisper Large V3
- **Translated content** through fine-tuned Swahili-English translation models
- **Automated case triage predictions** using BERT-based classification

The service integrates directly with helpline case management systems, enabling **AI-assisted triage as part of the operational case workflow**. End-to-end functional testing confirms reliable operation across all pipeline stages.

### Optimized Data Flow

Data flows seamlessly across the transcription, translation, and case prediction triage modules with reliable handoffs between each pipeline stage:

- **Seamless data transfer** across modules with no loss of information
- **Zero processing gaps** or workflow interruptions
- **Real-time handoffs** with validated latency and performance characteristics
- **Stable interoperability** confirmed through system logs and data flow validation

The complete pipeline flow ensures that outputs from transcription feed correctly into translation and downstream case triage prediction in real time, demonstrating stable end-to-end interoperability.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UNIFIED PIPELINE - FULLY INTEGRATED                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   Audio/Voice Input                                                          â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚
â”‚   â”‚  TRANSCRIPTION  â”‚  Whisper Large V3 (99+ languages)                     â”‚
â”‚   â”‚   (Complete)    â”‚  Real-time streaming or batch processing               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚            â”‚ â† Seamless handoff, no data loss                                â”‚
â”‚            â–¼                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚
â”‚   â”‚   TRANSLATION   â”‚  Fine-tuned Swahili â†” English                         â”‚
â”‚   â”‚   (Complete)    â”‚  Context-aware chunking with overlap                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚            â”‚ â† Optimized data flow, zero gaps                                â”‚
â”‚            â–¼                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚   â”‚            CASE TRIAGE PREDICTION            â”‚                           â”‚
â”‚   â”‚               (Complete)                     â”‚                           â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                           â”‚
â”‚   â”‚  â”‚   NER    â”‚ â”‚ Classify â”‚ â”‚  Summarize   â”‚ â”‚                           â”‚
â”‚   â”‚  â”‚ (spaCy)  â”‚ â”‚ (BERT)   â”‚ â”‚  (BART/T5)   â”‚ â”‚                           â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚            â”‚ â† Real-time updates during calls                                â”‚
â”‚            â–¼                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚
â”‚   â”‚ STRUCTURED      â”‚  Risk assessment, priority, recommendations            â”‚
â”‚   â”‚ INSIGHTS        â”‚  Integrated with helpline case management              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Status

| Component | Status | Details |
|-----------|--------|---------|
| Speech-to-Text Transcription | Operational | Whisper Large V3, 99+ languages |
| Multilingual Translation | Operational | Fine-tuned Swahili â†” English |
| Case Prediction Triage | Operational | BERT-based classification with NER |
| Data Flow | Optimized | Seamless handoffs, zero data loss |
| Helpline Integration | Operational | Real-time and post-call processing |

---

## Overview

This system processes audio files through a complete AI pipeline:
**Audio â†’ Transcription â†’ Translation â†’ NLP Analysis â†’ Structured Insights**

### Key Capabilities

- **ğŸ™ï¸ Speech-to-Text**: Whisper Large V3 Turbo with 99+ language support, streaming and batch modes
- **ğŸŒ Translation**: Fine-tuned Swahili â†” English translation with context-aware chunking
- **ğŸ§  NLP Analysis**: Named Entity Recognition, Classification, Summarization - all integrated
- **ğŸ”— Unified Pipeline**: Single workflow processing from audio input to case triage output
- **âš¡ Real-time Processing**: GPU-accelerated with optimized data flow between modules
- **ğŸ“Š Production Ready**: Comprehensive monitoring, error handling, and horizontal scalability
- **ğŸ¥ Helpline Integration**: Directly integrated with case management systems for operational triage

### Target Use Cases

- **Helpline Case Management**: AI-assisted triage integrated directly into operational workflows
- **Child Protection Services**: Analyze crisis calls and case recordings with automated prioritization
- **Social Services**: Process client interviews and assessment calls with structured insights
- **Healthcare**: Mental health crisis detection, triage, and intervention recommendations
- **Emergency Services**: Rapid case classification, priority assessment, and risk analysis

## Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FastAPI Gateway (Port 8125)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Audio Upload     â”‚   â”‚ Asterisk Stream  â”‚   â”‚ SCP/HTTP Download        â”‚ â”‚
â”‚  â”‚ (HTTP POST)      â”‚   â”‚ (TCP Port 8301)  â”‚   â”‚ (Post-Call)              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                      â”‚                      â”‚                    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                  â–¼                                           â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚    Celery Task Queue    â”‚                               â”‚
â”‚                    â”‚   (Redis Broker)        â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                â”‚                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    INTEGRATED PROCESSING PIPELINE                            â”‚
â”‚                                â–¼                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚   Whisper   â”‚ â†’ â”‚ Translation â”‚ â†’ â”‚       Case Triage Models        â”‚   â”‚
â”‚   â”‚ Transcribe  â”‚   â”‚   (Swâ†”En)   â”‚   â”‚   NER  â”‚  Classify  â”‚  Summarizeâ”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                  â”‚                         â”‚                       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                            â–¼                                                 â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚                  â”‚  Structured Output   â”‚                                    â”‚
â”‚                  â”‚  + Notifications     â”‚                                    â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Redis Queue + GPU Resource Management + Monitoring              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Modes

The integrated pipeline supports three processing modes for different operational needs:

| Mode | Description | Use Case |
|------|-------------|----------|
| **Real-time Streaming** | Progressive updates every 5-30 seconds during live calls | Live call assistance, immediate agent support |
| **Post-Call Processing** | Complete pipeline analysis after call ends | Detailed case analysis, quality review |
| **Adaptive/Dual Mode** | Intelligent selection based on call characteristics | Balanced approach for production environments |

**Real-time Data Flow:**
- Audio chunks received every 10ms (320 bytes SLIN format)
- Transcription updates every 5 seconds
- Translation and NER/Classification updates every 30 seconds
- Agent notifications sent progressively during call
- Cumulative transcript maintained throughout session

### Technology Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **API Framework** | FastAPI 0.116+ | Async REST API with automatic documentation |
| **Task Queue** | Celery + Redis | Distributed audio processing |
| **ML Framework** | PyTorch + Transformers | Model inference and GPU management |
| **Audio Processing** | Librosa + SoundFile | Audio format handling and preprocessing |
| **NLP Engine** | spaCy + Custom Models | Entity extraction and text analysis |
| **Containerization** | Docker + Docker Compose | Production deployment |
| **Monitoring** | Built-in health checks | Resource monitoring and alerting |

## ğŸš€ Quick Start

### Prerequisites

- **Hardware**: GPU recommended (16GB+ VRAM), 32GB+ RAM, 24+ CPU cores
- **Software**: Docker 20.10+, Docker Compose 2.0+, NVIDIA Container Runtime (for GPU)

### 1. Clone and Setup

```bash
git clone <repository-url>
cd ai-pipeline-containerized

# Copy environment template
cp .env.example .env

# Review and adjust configuration
nano .env
```

### 2. Start with Docker Compose

```bash
# Production deployment
docker-compose up -d

# Development with hot reload
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up
```

### 3. Verify Installation

```bash
# Check API health
curl http://localhost:8123/health/detailed

# Check worker status
curl http://localhost:8123/audio/workers/status

# Access API documentation
open http://localhost:8123/docs
```

### 4. Process Your First Audio File

```bash
# Upload and process audio file
curl -X POST \
  -F "audio=@sample.wav" \
  -F "language=sw" \
  -F "include_translation=true" \
  http://localhost:8123/audio/process

# Real-time streaming updates
curl -X POST \
  -F "audio=@sample.wav" \
  -F "language=sw" \
  http://localhost:8123/audio/process-stream
```

## ğŸ“‹ API Documentation

### Core Endpoints

#### Audio Processing
```http
POST /audio/process          # Complete pipeline analysis
POST /audio/analyze          # Quick analysis (essentials only)
POST /audio/process-stream   # Real-time streaming updates
GET  /audio/task/{task_id}   # Check processing status
```

#### Individual Models
```http
POST /whisper/transcribe     # Audio transcription
POST /translate/             # Text translation
POST /ner/extract           # Named entity recognition
POST /classifier/classify    # Case classification
POST /summarizer/summarize   # Text summarization
```

#### System Monitoring
```http
GET /health/detailed         # Comprehensive system status
GET /health/models          # Model loading status
GET /audio/queue/status     # Processing queue status
GET /audio/workers/status   # Celery worker status
```

### Example Response - Integrated Pipeline Output

The unified pipeline produces comprehensive, structured output combining all stages:

```json
{
  "status": "completed",
  "call_id": "CALL-2024-001234",
  "processing_mode": "post_call",
  "audio_info": {
    "filename": "crisis_call.wav",
    "file_size_mb": 2.3,
    "duration_seconds": 145.2,
    "language_detected": "sw",
    "processing_time_seconds": 23.4
  },
  "transcription": {
    "text": "Msichana mdogo ana miaka 12 na ana matatizo ya akili...",
    "language": "sw",
    "confidence": 0.96,
    "segments": [
      {"start": 0.0, "end": 5.2, "text": "Msichana mdogo ana miaka 12..."}
    ]
  },
  "translation": {
    "source_language": "sw",
    "target_language": "en",
    "translated_text": "A 12-year-old girl is experiencing mental health issues...",
    "chunk_count": 3
  },
  "entities": {
    "PERSON": ["Maria", "Dr. John Omondi"],
    "LOC": ["Nairobi", "Kibera"],
    "ORG": ["Kenyatta Hospital"],
    "DATE": ["yesterday", "two weeks ago"],
    "AGE": ["12 years old"]
  },
  "classification": {
    "main_category": "child_protection",
    "sub_category": "mental_health_crisis",
    "intervention_type": "immediate_psychiatric_evaluation",
    "priority": "high",
    "confidence": 0.94,
    "chunk_predictions": [
      {"position": "beginning", "category": "child_protection", "confidence": 0.92},
      {"position": "middle", "category": "mental_health", "confidence": 0.96},
      {"position": "end", "category": "crisis_intervention", "confidence": 0.91}
    ]
  },
  "summary": {
    "executive_summary": "12-year-old girl experiencing acute mental health crisis requiring immediate psychiatric evaluation and family support services.",
    "key_points": [
      "Child age: 12 years old",
      "Location: Kibera, Nairobi",
      "Condition: Mental health crisis",
      "Duration: Symptoms present for two weeks"
    ]
  },
  "insights": {
    "risk_assessment": {
      "risk_level": "high",
      "confidence": 0.91,
      "factors": ["age_vulnerability", "mental_health_indicators", "crisis_keywords"]
    },
    "recommended_disposition": "immediate_psychiatric_evaluation",
    "suggested_categories": [
      {"category": "child_protection", "probability": 0.94},
      {"category": "mental_health", "probability": 0.89},
      {"category": "family_support", "probability": 0.72}
    ],
    "priority_score": 0.92
  },
  "pipeline_metrics": {
    "transcription_time_ms": 8420,
    "translation_time_ms": 5230,
    "ner_time_ms": 1850,
    "classification_time_ms": 3420,
    "summarization_time_ms": 4280,
    "total_pipeline_time_ms": 23400,
    "data_handoff_validations": "passed"
  }
}
```

### Data Flow Validation

The integrated pipeline includes built-in validation to ensure reliable handoffs:

| Handoff Point | Validation | Status |
|---------------|------------|--------|
| Audio â†’ Transcription | Format validation, duration check | Validated |
| Transcription â†’ Translation | Text completeness, encoding check | Validated |
| Translation â†’ NER | Character length, language verification | Validated |
| Translation â†’ Classification | Chunk boundaries, context overlap | Validated |
| All Modules â†’ Output | Schema validation, completeness check | Validated |

## Helpline Case Management Integration

The AI pipeline has been integrated directly into the helpline case management workflow, enabling AI-assisted triage as part of operational case processing.

### Integration Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HELPLINE CASE MANAGEMENT SYSTEM                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  Asterisk   â”‚  TCP   â”‚   AI Pipeline   â”‚  HTTP  â”‚  Case Manager   â”‚    â”‚
â”‚   â”‚    PBX      â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   (Port 8301)   â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    System       â”‚    â”‚
â”‚   â”‚             â”‚        â”‚                 â”‚        â”‚                 â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                        â”‚                          â”‚              â”‚
â”‚         â”‚                        â”‚                          â”‚              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚   Live    â”‚          â”‚  Progressive  â”‚          â”‚   Agent UI    â”‚     â”‚
â”‚   â”‚   Calls   â”‚          â”‚  Transcriptionâ”‚          â”‚   Dashboard   â”‚     â”‚
â”‚   â”‚           â”‚          â”‚  & Analysis   â”‚          â”‚   & Alerts    â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Operational Workflow

1. **Call Initiation**: Asterisk PBX streams live audio to AI Pipeline via TCP
2. **Real-time Processing**: Pipeline processes audio in 5-30 second windows
3. **Progressive Updates**: Transcription, translation, and triage predictions sent to agents
4. **Case Triage**: Automated classification, priority assignment, and recommendations
5. **Agent Notification**: Results pushed to case management system for agent review
6. **Post-Call Analysis**: Complete analysis stored for case documentation

### Agent Notification System

The pipeline sends structured notifications to agents during and after calls:

```json
{
  "notification_type": "progressive_update",
  "call_id": "CALL-2024-001234",
  "agent_id": "agent_042",
  "timestamp": "2024-01-15T10:23:45Z",
  "data": {
    "transcript_update": "Child reports feeling unsafe at home...",
    "current_classification": {
      "category": "child_protection",
      "priority": "high"
    },
    "entities_detected": ["child", "home", "unsafe"],
    "recommended_action": "Escalate to supervisor"
  }
}
```

### Configuration for Helpline Integration

```bash
# Notification endpoint configuration
NOTIFICATION_ENDPOINT_URL=https://your-helpline-system/api/msg/
NOTIFICATION_BASIC_AUTH=<base64-encoded-credentials>
ENABLE_AGENT_NOTIFICATIONS=true
NOTIFICATION_MODE=progressive  # or results_only

# Asterisk streaming configuration
ENABLE_STREAMING=true
STREAMING_PORT=8301
STREAMING_HOST=0.0.0.0
STREAMING_TRANSCRIPTION_INTERVAL=5
STREAMING_TRANSLATION_INTERVAL=30
```

## âš™ï¸ Configuration

### Environment Variables

```bash
# Core Application
APP_NAME="AI Pipeline"
DEBUG=false
LOG_LEVEL=INFO

# Resource Management
MAX_CONCURRENT_GPU_REQUESTS=1
MAX_QUEUE_SIZE=20
REQUEST_TIMEOUT=300

# Model Configuration
ENABLE_MODEL_LOADING=true
MODEL_CACHE_SIZE=8192

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
REDIS_TASK_DB=1

# Security
SITE_ID=production-001
DATA_RETENTION_HOURS=24
```

### Hardware Optimization

#### For GPU Servers (Recommended)
```yaml
# docker-compose.gpu.yml
services:
  ai-pipeline:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 32G
    environment:
      - MAX_CONCURRENT_GPU_REQUESTS=1
      - ENABLE_MODEL_LOADING=true
```

#### For CPU-Only Deployment
```yaml
# docker-compose.cpu.yml
services:
  ai-pipeline:
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8'
    environment:
      - MAX_CONCURRENT_GPU_REQUESTS=2
      - ENABLE_MODEL_LOADING=true
```

## ğŸ”§ Production Deployment

### Docker Production Stack

```yaml
version: '3.8'
services:
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - redis_data:/data

  ai-pipeline:
    build: .
    restart: unless-stopped
    depends_on:
      - redis
    environment:
      - DEBUG=false
      - LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./models:/app/models
      - ./logs:/app/logs
    ports:
      - "8123:8123"

  celery-worker:
    build: .
    restart: unless-stopped
    depends_on:
      - redis
    command: celery -A app.celery_app worker --loglevel=info -E --pool=solo
    environment:
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./models:/app/models
      - ./logs:/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  nginx:
    image: nginx:alpine
    restart: unless-stopped
    depends_on:
      - ai-pipeline
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl

volumes:
  redis_data:
```

### Scaling Configuration

#### Horizontal Scaling
```bash
# Scale workers for higher throughput
docker-compose up --scale celery-worker=3

# Load balancer configuration
# Multiple API instances behind nginx
docker-compose up --scale ai-pipeline=2
```

#### Kubernetes Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-pipeline
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-pipeline
  template:
    spec:
      containers:
      - name: ai-pipeline
        image: ai-pipeline:latest
        resources:
          requests:
            memory: "16Gi"
            nvidia.com/gpu: 1
          limits:
            memory: "32Gi"
            nvidia.com/gpu: 1
```

## ğŸ“Š Monitoring & Observability

### Built-in Health Checks

```bash
# System health with detailed metrics
curl http://localhost:8123/health/detailed

# Model status and dependencies
curl http://localhost:8123/health/models

# Resource utilization
curl http://localhost:8123/health/resources

# Processing queue status
curl http://localhost:8123/audio/queue/status
```

### Logging Configuration

```python
# Production logging setup
LOGGING_CONFIG = {
    "version": 1,
    "handlers": {
        "file": {
            "class": "logging.handlers.RotatingFileHandler",
            "filename": "/app/logs/ai-pipeline.log",
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5
        }
    },
    "loggers": {
        "app": {"level": "INFO", "handlers": ["file"]},
        "celery": {"level": "WARNING", "handlers": ["file"]}
    }
}
```

### Prometheus Metrics (Optional)

```python
# Add to requirements.txt
prometheus-client==0.17.1

# Metrics endpoint
curl http://localhost:8123/metrics
```

## ğŸ§ª Testing

### Unit Tests
```bash
# Run test suite
python -m pytest tests/ -v

# Test specific components
python -m pytest tests/test_text_chunker.py -v
python -m pytest tests/test_models.py -v

# Coverage report
python -m pytest --cov=app tests/
```

### Integration Tests
```bash
# Test complete audio pipeline
python -m pytest tests/test_integration.py

# Load testing
python scripts/load_test.py --concurrent-requests=10
```

### Model Validation
```bash
# Validate model outputs
python scripts/validate_models.py

# Benchmark performance
python scripts/benchmark_models.py
```

## ğŸ› ï¸ Development

### Local Development Setup

```bash
# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install spaCy model
python -m spacy download en_core_web_lg

# Start development server
python -m app.main
```

### Adding New Models

1. **Create Model Wrapper**
```python
# app/models/your_model.py
class YourModel:
    def load(self) -> bool:
        # Model loading logic
        pass
    
    def process(self, input_data):
        # Model inference logic
        pass
    
    def get_model_info(self) -> Dict:
        # Model metadata
        pass

your_model = YourModel()
```

2. **Register with Model Loader**
```python
# app/models/model_loader.py
self.model_dependencies["your_model"] = {
    "required": ["torch", "transformers"],
    "description": "Your model description"
}
```

3. **Add API Endpoints**
```python
# app/api/your_model_routes.py
@router.post("/your-model/process")
async def process_with_your_model(request: YourRequest):
    # API endpoint logic
    pass
```

### MLOps Best Practices Implemented

- **âœ… Model Versioning**: Models loaded from versioned paths with metadata tracking
- **âœ… Experiment Tracking**: Integration-ready for MLflow experiment tracking
- **âœ… Resource Management**: GPU memory management and request queuing
- **âœ… Error Handling**: Comprehensive error handling with fallback strategies
- **âœ… Monitoring**: Built-in health checks and performance metrics
- **âœ… Scalability**: Horizontal scaling with Celery workers
- **âœ… CI/CD Ready**: Docker-based deployment with environment configuration

## ğŸ”’ Security Considerations

### Data Privacy
- **Local Processing**: All audio processing happens offline
- **No External Calls**: No data sent to external APIs
- **Data Retention**: Configurable data retention policies
- **PII Handling**: Automatic detection and handling of sensitive information

### Production Security
```bash
# Secure configuration
SECURE_SSL_REDIRECT=True
SESSION_COOKIE_SECURE=True
CSRF_COOKIE_SECURE=True

# Rate limiting
MAX_REQUESTS_PER_MINUTE=60
MAX_FILE_SIZE_MB=100

# Authentication (implement as needed)
ENABLE_AUTH=True
JWT_SECRET_KEY=your-secret-key
```

## ğŸ“ˆ Performance Benchmarks

### Typical Performance (GPU-enabled)
- **Audio Transcription**: 2-5 seconds per minute of audio
- **Complete Pipeline**: 15-45 seconds for 2-minute audio file
- **Throughput**: 10+ concurrent requests with queue management
- **Memory Usage**: ~8GB GPU VRAM, ~16GB system RAM

### Optimization Tips
```bash
# Model optimization
TORCH_DTYPE=float16          # Reduce memory usage
BATCH_SIZE=1                 # GPU memory management
ENABLE_CHUNKING=true         # Handle long audio files

# System optimization
OMP_NUM_THREADS=8            # CPU optimization
CUDA_VISIBLE_DEVICES=0       # GPU selection
```

## ğŸ¤ Contributing

### Development Workflow
1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Make changes with tests: `python -m pytest tests/`
4. Commit changes: `git commit -m "Add amazing feature"`
5. Push to branch: `git push origin feature/amazing-feature`
6. Open Pull Request

### Code Standards
- **Python**: Follow PEP 8, use type hints
- **Tests**: Maintain >80% test coverage
- **Documentation**: Update README and API docs
- **Docker**: Test containerized deployment

## ğŸ“š Additional Resources

### Documentation
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Celery Documentation](https://docs.celeryproject.org/)
- [Transformers Documentation](https://huggingface.co/docs/transformers/)
- [MLOps Best Practices](https://ml-ops.org/)

### Model Information
- **Whisper Large V3 Turbo**: OpenAI's latest speech recognition model
- **Custom Translation**: Fine-tuned for Swahili-English translation
- **spaCy NER**: English language model for entity recognition
- **DistilBERT**: Fine-tuned for case classification

### Community
- **Issues**: Report bugs and request features
- **Discussions**: Technical discussions and use cases
- **Wiki**: Deployment guides and troubleshooting

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenAI for Whisper model
- Hugging Face for Transformers library
- spaCy team for NLP tools
- FastAPI and Celery communities

---

## Production Status

This AI Pipeline is **production-ready** with full end-to-end integration:

- **Unified Pipeline**: All AI components (transcription, translation, case triage) operate as a single cohesive service
- **Optimized Data Flow**: Seamless data transfer between pipeline stages with zero information loss
- **Helpline Integration**: Operational within case management workflows
- **End-to-End Tested**: Comprehensive functional testing across all pipeline stages
- **Real-time Capable**: Progressive updates during live calls with reliable module handoffs

---

**Built for Social Impact**

Designed to help child protection and social services organizations make faster, more informed decisions to protect vulnerable populations. The integrated pipeline transforms voice and text inputs into actionable case insights within a single, reliable workflow.

For support and questions, please open an issue or reach out to the development team.