"""
Whisper Model Manager for dynamic model switching and translation strategy management
Handles multiple whisper variants and coordinates with translation models
"""
import logging
import os
import gc
import torch
from typing import Optional, Dict, Any, Tuple, List
from datetime import datetime
from enum import Enum

logger = logging.getLogger(__name__)

class WhisperVariant(Enum):
    """Available Whisper model variants"""
    LARGE_V3 = "large_v3"          # Full model with built-in translation
    LARGE_TURBO = "large_turbo"    # Lighter model for transcription only

class TranslationStrategy(Enum):
    """Translation strategies"""
    WHISPER_BUILTIN = "whisper_builtin"    # Use Whisper's built-in translation
    CUSTOM_MODEL = "custom_model"          # Use separate translation model

class WhisperModelManager:
    """
    Manages multiple Whisper model variants and coordinates translation strategies
    Only one Whisper model is loaded in memory at a time
    """
    
    def __init__(self):
        from ..config.settings import settings
        
        self.settings = settings
        self.current_variant: Optional[WhisperVariant] = None
        self.current_strategy: Optional[TranslationStrategy] = None
        self.whisper_model = None  # Currently loaded WhisperModel instance
        
        # Model paths
        self.variant_paths = {
            WhisperVariant.LARGE_V3: settings.whisper_large_v3_path,
            WhisperVariant.LARGE_TURBO: settings.whisper_large_turbo_path
        }
        
        # Load initial configuration
        self._load_initial_config()
        
        logger.info(f"üéõÔ∏è WhisperModelManager initialized: {self.current_variant.value} + {self.current_strategy.value}")
    
    def _load_initial_config(self):
        """Load initial configuration from settings"""
        try:
            # Parse variant from settings
            variant_str = self.settings.whisper_model_variant.lower()
            if variant_str == "large_v3":
                self.current_variant = WhisperVariant.LARGE_V3
            elif variant_str == "large_turbo":
                self.current_variant = WhisperVariant.LARGE_TURBO
            else:
                logger.warning(f"Unknown whisper variant '{variant_str}', defaulting to large_turbo")
                self.current_variant = WhisperVariant.LARGE_TURBO
            
            # Parse translation strategy
            strategy_str = self.settings.translation_strategy.lower()
            if strategy_str == "whisper_builtin":
                self.current_strategy = TranslationStrategy.WHISPER_BUILTIN
            elif strategy_str == "custom_model":
                self.current_strategy = TranslationStrategy.CUSTOM_MODEL
            else:
                logger.warning(f"Unknown translation strategy '{strategy_str}', defaulting to custom_model")
                self.current_strategy = TranslationStrategy.CUSTOM_MODEL
            
            # Auto-upgrade to Large-V3 when whisper_builtin is configured
            if self.current_strategy == TranslationStrategy.WHISPER_BUILTIN and self.current_variant != WhisperVariant.LARGE_V3:
                logger.info(f"üéØ Auto-upgrading from {self.current_variant.value} to large_v3 for built-in translation")
                self.current_variant = WhisperVariant.LARGE_V3
            
            # Validate configuration combination (fallback safety)
            if self.current_variant == WhisperVariant.LARGE_TURBO and self.current_strategy == TranslationStrategy.WHISPER_BUILTIN:
                logger.warning("‚ö†Ô∏è Invalid combination: large_turbo doesn't support built-in translation, switching to custom_model")
                self.current_strategy = TranslationStrategy.CUSTOM_MODEL
                
        except Exception as e:
            logger.error(f"‚ùå Failed to load whisper config: {e}")
            # Safe defaults
            self.current_variant = WhisperVariant.LARGE_TURBO
            self.current_strategy = TranslationStrategy.CUSTOM_MODEL
    
    def get_current_model_path(self) -> str:
        """Get path to currently configured whisper model"""
        return os.path.abspath(self.variant_paths[self.current_variant])
    
    def is_model_loaded(self) -> bool:
        """Check if whisper model is currently loaded"""
        return self.whisper_model is not None and getattr(self.whisper_model, 'is_loaded', False)
    
    def get_loaded_variant_info(self) -> Dict[str, Any]:
        """Get standardized information about currently loaded model variant"""
        
        info = {
            "model_type": "whisper_variant_info",
            "loaded": self.is_model_loaded(),
            "load_time": None, # Not directly tracked by manager for this level
            "device": self.whisper_model.device if self.whisper_model else None,
            "error": self.whisper_model.error if self.whisper_model else None,
        }

        details = {
            "variant": self.current_variant.value if self.current_variant else None,
            "strategy": self.current_strategy.value if self.current_strategy else None,
            "model_path": self.get_current_model_path(),
            "supports_builtin_translation": self.current_variant == WhisperVariant.LARGE_V3,
            "translation_strategy_active": self.current_strategy.value,
        }

        if self.is_model_loaded():
            details["model_info"] = self.whisper_model.get_model_info()
        
        info["details"] = details
        return info
    
    async def load_whisper_model(self, force_reload: bool = False) -> bool:
        """
        Load the currently configured whisper model
        
        Args:
            force_reload: Force reload even if model is already loaded
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Check if already loaded and no reload needed
            if self.is_model_loaded() and not force_reload:
                logger.info(f"‚úÖ Whisper model already loaded: {self.current_variant.value}")
                return True
            
            # Unload existing model if any
            await self._unload_current_model()
            
            # Update symlink to point to current variant
            self._update_symlink()
            
            # Create new WhisperModel instance with specific path
            from ..model_scripts.whisper_model import WhisperModel
            
            model_path = self.get_current_model_path()
            logger.info(f"üéôÔ∏è Loading Whisper {self.current_variant.value} from {model_path}")
            
            # Enable translation for Large-V3, disable for Large-Turbo
            enable_translation = (self.current_variant == WhisperVariant.LARGE_V3)
            
            self.whisper_model = WhisperModel(
                model_path=model_path,
                enable_translation=enable_translation
            )
            
            logger.info(f"üéØ Model configuration: translation_enabled={enable_translation}")
            
            # Load the model
            success = self.whisper_model.load()
            
            if success:
                logger.info(f"‚úÖ Successfully loaded Whisper {self.current_variant.value}")
                logger.info(f"üéØ Translation strategy: {self.current_strategy.value}")
                return True
            else:
                logger.error(f"‚ùå Failed to load Whisper {self.current_variant.value}")
                self.whisper_model = None
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error loading Whisper model: {e}")
            self.whisper_model = None
            return False
    
    async def switch_model_variant(self, new_variant: WhisperVariant, 
                                 new_strategy: Optional[TranslationStrategy] = None) -> bool:
        """
        Switch to a different Whisper model variant
        
        Args:
            new_variant: The whisper variant to switch to
            new_strategy: Optional new translation strategy
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Validate the combination
            if new_variant == WhisperVariant.LARGE_TURBO and new_strategy == TranslationStrategy.WHISPER_BUILTIN:
                logger.error("‚ùå Invalid combination: large_turbo doesn't support built-in translation")
                return False
            
            # Check if model path exists
            new_model_path = self.variant_paths[new_variant]
            if not os.path.exists(new_model_path):
                logger.error(f"‚ùå Model path doesn't exist: {new_model_path}")
                return False
            
            logger.info(f"üîÑ Switching from {self.current_variant.value} to {new_variant.value}")
            
            # Update configuration
            old_variant = self.current_variant
            old_strategy = self.current_strategy
            
            self.current_variant = new_variant
            if new_strategy:
                self.current_strategy = new_strategy
            
            # Reload the model
            success = await self.load_whisper_model(force_reload=True)
            
            if success:
                logger.info(f"‚úÖ Successfully switched to Whisper {new_variant.value}")
                return True
            else:
                # Rollback on failure
                logger.error(f"‚ùå Failed to switch models, rolling back")
                self.current_variant = old_variant
                self.current_strategy = old_strategy
                await self.load_whisper_model(force_reload=True)
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error switching Whisper variant: {e}")
            return False
    
    async def _unload_current_model(self):
        """Unload currently loaded model to free memory"""
        if self.whisper_model:
            try:
                # Clear model references
                if hasattr(self.whisper_model, 'model') and self.whisper_model.model:
                    del self.whisper_model.model
                if hasattr(self.whisper_model, 'processor') and self.whisper_model.processor:
                    del self.whisper_model.processor
                if hasattr(self.whisper_model, 'pipe') and self.whisper_model.pipe:
                    del self.whisper_model.pipe
                
                self.whisper_model = None
                
                # Force garbage collection
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                logger.info("üóëÔ∏è Unloaded previous Whisper model and cleared memory")
                
            except Exception as e:
                logger.error(f"‚ö†Ô∏è Error during model unload: {e}")
    
    def _update_symlink(self):
        """Update the whisper symlink to point to current variant"""
        try:
            symlink_path = os.path.abspath(self.settings.whisper_active_symlink)
            target_path = os.path.basename(self.get_current_model_path())
            
            # Remove existing symlink
            if os.path.islink(symlink_path):
                os.unlink(symlink_path)
            elif os.path.exists(symlink_path):
                logger.warning(f"‚ö†Ô∏è {symlink_path} exists but is not a symlink, removing")
                os.remove(symlink_path)
            
            # Create new symlink
            os.symlink(target_path, symlink_path)
            
            logger.info(f"üîó Updated symlink: whisper -> {target_path}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to update whisper symlink: {e}")
    
    def should_use_whisper_translation(self) -> bool:
        """Determine if whisper should handle translation or if custom model should be used"""
        return (
            self.current_strategy == TranslationStrategy.WHISPER_BUILTIN and 
            self.current_variant == WhisperVariant.LARGE_V3
        )
    
    def should_use_custom_translation(self) -> bool:
        """Determine if custom translation model should be used"""
        return self.current_strategy == TranslationStrategy.CUSTOM_MODEL
    
    def get_recommended_translation_strategy(self, variant: WhisperVariant) -> TranslationStrategy:
        """Get recommended translation strategy for a given variant"""
        if variant == WhisperVariant.LARGE_V3:
            # Large-v3 can do both, prefer built-in for speed
            return TranslationStrategy.WHISPER_BUILTIN
        else:
            # Large-turbo can only do transcription
            return TranslationStrategy.CUSTOM_MODEL
    
    def get_available_combinations(self) -> List[Dict[str, str]]:
        """Get all valid whisper variant + translation strategy combinations"""
        return [
            {
                "variant": "large_turbo",
                "strategy": "custom_model", 
                "description": "Fast transcription + custom translation model"
            },
            {
                "variant": "large_v3",
                "strategy": "whisper_builtin",
                "description": "Whisper large-v3 transcription + built-in translation"
            },
            {
                "variant": "large_v3", 
                "strategy": "custom_model",
                "description": "Whisper large-v3 transcription + custom translation model"
            }
        ]
    
    def transcribe_with_strategy(self, audio_bytes: bytes, language: str = "sw") -> Dict[str, Any]:
        """
        Transcribe audio with current strategy configuration
        
        Returns:
            Dict containing transcript and translation based on current strategy
        """
        if not self.is_model_loaded():
            raise RuntimeError("No Whisper model loaded")
        
        try:
            start_time = datetime.now()
            
            # Always get transcript
            transcript = self.whisper_model.transcribe_audio_bytes(audio_bytes, language)
            
            result = {
                "transcript": transcript,
                "translation": None,
                "variant_used": self.current_variant.value,
                "strategy_used": self.current_strategy.value,
                "processing_time_seconds": (datetime.now() - start_time).total_seconds()
            }
            
            # Handle translation based on strategy
            if self.should_use_whisper_translation():
                # Use Whisper's built-in translation (large-v3 only)
                logger.info(f"üåê Using Whisper built-in translation")
                try:
                    # Re-process with translation task
                    translation = self._transcribe_with_translation_task(audio_bytes, language)
                    result["translation"] = translation
                    result["translation_source"] = "whisper_builtin"
                except Exception as e:
                    logger.error(f"‚ùå Whisper translation failed: {e}")
                    result["translation_error"] = str(e)
            
            elif self.should_use_custom_translation():
                # Translation will be handled by separate translation model
                logger.info(f"üåê Custom translation model will handle translation")
                result["translation_source"] = "custom_model_pending"
                result["requires_custom_translation"] = True
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Transcription with strategy failed: {e}")
            raise
    
    def _transcribe_with_translation_task(self, audio_bytes: bytes, language: str) -> str:
        """Use Whisper's built-in translation capability (large-v3 only)"""
        if self.current_variant != WhisperVariant.LARGE_V3:
            raise RuntimeError("Built-in translation only available with large-v3 variant")
        
        if not self.whisper_model or not self.whisper_model.is_ready():
            raise RuntimeError("Whisper model not loaded or not ready")
        
        try:
            logger.info("üåê Using Whisper built-in translation to English")
            # Use WhisperModel with translation task
            result = self.whisper_model.transcribe_audio_bytes(audio_bytes, language=language, task="translate")
            logger.info(f"‚úÖ Whisper built-in translation completed: {len(result)} characters")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Whisper translation failed: {e}")
            raise
    
    async def get_model_status(self) -> Dict[str, Any]:
        """Get comprehensive status of whisper models and configuration"""
        
        info = {
            "model_type": "whisper_manager",
            "loaded": self.is_model_loaded(),
            "load_time": None, # Not directly tracked by manager
            "device": self.whisper_model.device if self.whisper_model else None,
            "error": self.whisper_model.error if self.whisper_model else None,
        }

        details = {
            "current_configuration": {
                "variant": self.current_variant.value if self.current_variant else None,
                "strategy": self.current_strategy.value if self.current_strategy else None,
                "model_loaded": self.is_model_loaded()
            },
            "available_variants": [v.value for v in WhisperVariant],
            "available_strategies": [s.value for s in TranslationStrategy],
            "valid_combinations": self.get_available_combinations(),
            "model_paths": {
                "large_v3": os.path.abspath(self.variant_paths[WhisperVariant.LARGE_V3]),
                "large_turbo": os.path.abspath(self.variant_paths[WhisperVariant.LARGE_TURBO]),
                "symlink": os.path.abspath(self.settings.whisper_active_symlink)
            },
            "model_status": {
                "large_v3_available": os.path.exists(self.variant_paths[WhisperVariant.LARGE_V3]),
                "large_turbo_available": os.path.exists(self.variant_paths[WhisperVariant.LARGE_TURBO]),
                "current_model_path": self.get_current_model_path() if self.current_variant else None
            },
            "loaded_model_info": self.get_loaded_variant_info(),
            "memory_status": {
                "cuda_available": torch.cuda.is_available(),
                "cuda_memory_allocated": torch.cuda.memory_allocated() if torch.cuda.is_available() else 0,
                "cuda_memory_reserved": torch.cuda.memory_reserved() if torch.cuda.is_available() else 0
            }
        }
        info["details"] = details
        return info
    
    async def switch_configuration(self, variant: str, strategy: str) -> Tuple[bool, str]:
        """
        Switch whisper configuration (variant + translation strategy)
        
        Args:
            variant: "large_v3" or "large_turbo"
            strategy: "whisper_builtin" or "custom_model"
            
        Returns:
            Tuple of (success, message)
        """
        try:
            # Parse and validate inputs
            try:
                new_variant = WhisperVariant(variant)
            except ValueError:
                return False, f"Invalid variant: {variant}. Must be 'large_v3' or 'large_turbo'"
            
            try:
                new_strategy = TranslationStrategy(strategy)
            except ValueError:
                return False, f"Invalid strategy: {strategy}. Must be 'whisper_builtin' or 'custom_model'"
            
            # Validate combination
            if new_variant == WhisperVariant.LARGE_TURBO and new_strategy == TranslationStrategy.WHISPER_BUILTIN:
                return False, "Invalid combination: large_turbo doesn't support built-in translation"
            
            # Check if model exists
            model_path = self.variant_paths[new_variant]
            if not os.path.exists(model_path):
                return False, f"Model not found: {model_path}"
            
            # Perform the switch
            success = await self.switch_model_variant(new_variant, new_strategy)
            
            if success:
                message = f"Successfully switched to {variant} with {strategy} translation"
                logger.info(f"‚úÖ {message}")
                return True, message
            else:
                message = f"Failed to switch to {variant}"
                logger.error(f"‚ùå {message}")
                return False, message
                
        except Exception as e:
            error_msg = f"Error switching configuration: {str(e)}"
            logger.error(f"‚ùå {error_msg}")
            return False, error_msg

# Global whisper model manager instance
whisper_model_manager = WhisperModelManager()