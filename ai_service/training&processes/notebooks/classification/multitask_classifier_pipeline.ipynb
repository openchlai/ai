{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81820d6e",
   "metadata": {},
   "source": [
    "# Case Classification Model Training Notebook\n",
    "This notebook trains a multi-label classification model for classifying cases repor in call center transcripts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6b81f",
   "metadata": {},
   "source": [
    "## 📦 Setup and Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231aa122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogendo/chl_scratch/mcreativity/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DistilBertPreTrainedModel,\n",
    "    DistilBertModel,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EvalPrediction\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import datetime\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import logging\n",
    "import dvc.api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Flow Experiment  initialization and Log configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://192.168.8.18:5000\")\n",
    "mlflow.set_experiment(\"Multitask_Classification\")\n",
    "\n",
    "\n",
    "REPO_ROOT=\"/home/rogendo/Work/ai/ai_service\"\n",
    "DATASET_PATH = 'datasets/classification/cleaned_synthetic_cases_generated_data_v0005.json'\n",
    "\n",
    "os.chdir(REPO_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4601fe8",
   "metadata": {},
   "source": [
    "### Dataset Loading\n",
    "\n",
    "In here we also Feature Engineer the Main-Category by mapping the subcategories against the pre-defined main categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816db175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh://ml-server-local/opt/dvc-storage/files/md5/e8/01db291a65ff08a5ac9611ccbee3d2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_dataset(dataset_path, version=\"HEAD\", repo=''):\n",
    "    \"\"\"Load dataset from DVC\"\"\"\n",
    "    # Get dataset path\n",
    "    data_url = dvc.api.get_url(\n",
    "        path = dataset_path,\n",
    "        repo=repo,\n",
    "    )\n",
    "\n",
    "\n",
    "    return data_url\n",
    "\n",
    "\n",
    "# load latest_version\n",
    "dataset_path = load_dataset(dataset_path=DATASET_PATH,repo=REPO_ROOT)\n",
    "print(dataset_path)\n",
    "df = pd.read_json(dataset_path)\n",
    "\n",
    "\n",
    "# df = pd.read_json(\"/home/rogendo/chl_scratch/synthetic_data/casedir/balanced_cases_generated_data_v0005.json\")\n",
    "# df = pd.read_json(\"/home/rogendo/chl_scratch/synthetic_data/casedir/cleaned_balanced_cases_generated_data_v0005.json\")\n",
    "sub_to_main_mapping = {\n",
    "    \"Bullying\": \"Advice and Counselling\",\n",
    "    \"Child in Conflict with the Law\": \"Advice and Counselling\",\n",
    "    \"Discrimination\": \"Advice and Counselling\",\n",
    "    \"Drug/Alcohol Abuse\": \"Advice and Counselling\",\n",
    "    \"Family Relationship\": \"Advice and Counselling\",\n",
    "    \"HIV/AIDS\": \"Advice and Counselling\",\n",
    "    \"Homelessness\": \"Advice and Counselling\",\n",
    "    \"Legal issues\": \"Advice and Counselling\",\n",
    "    \"Missing Child\": \"Advice and Counselling\",  \n",
    "    \"Peer Relationships\": \"Advice and Counselling\",\n",
    "    \"Physical Health\": \"Advice and Counselling\",\n",
    "    \"Psychosocial/Mental Health\": \"Advice and Counselling\",\n",
    "    \"Relationships (Boy/Girl)\": \"Advice and Counselling\",\n",
    "    \"Relationships (Parent/Child)\": \"Advice and Counselling\",\n",
    "    \"Relationships (Student/Teacher)\": \"Advice and Counselling\",\n",
    "    \"School related issues\": \"Advice and Counselling\",\n",
    "    \"Self Esteem\": \"Advice and Counselling\",\n",
    "    \"Sexual & Reproductive Health\": \"Advice and Counselling\",\n",
    "    \"Student/ Teacher Relationship\": \"Advice and Counselling\",\n",
    "    \"Teen Pregnancy\": \"Advice and Counselling\",\n",
    "    \"Adoption\": \"Child Maintenance & Custody\",\n",
    "    \"Birth Registration\": \"Child Maintenance & Custody\",\n",
    "    \"Custody\": \"Child Maintenance & Custody\",\n",
    "    \"Foster Care\": \"Child Maintenance & Custody\",\n",
    "    \"Maintenance\": \"Child Maintenance & Custody\",\n",
    "    \"No Care Giver\": \"Child Maintenance & Custody\",\n",
    "    \"Other\": \"Child Maintenance & Custody\", \n",
    "    \"Albinism\": \"Disability\",\n",
    "    \"Hearing impairment\": \"Disability\",\n",
    "    \"Hydrocephalus\": \"Disability\",\n",
    "    \"Mental impairment\": \"Disability\",\n",
    "    \"Multiple disabilities\": \"Disability\",\n",
    "    \"Physical impairment\": \"Disability\",\n",
    "    \"Speech impairment\": \"Disability\",\n",
    "    \"Spinal bifida\": \"Disability\",\n",
    "    \"Visual impairment\": \"Disability\",\n",
    "    \"Emotional/Psychological Violence\": \"GBV\",\n",
    "    \"Financial/Economic Violence\": \"GBV\",\n",
    "    \"Forced Marriage Violence\": \"GBV\",\n",
    "    \"Harmful Practice\": \"GBV\",\n",
    "    \"Physical Violence\": \"GBV\",\n",
    "    \"Sexual Violence\": \"GBV\",\n",
    "    \"Child Abuse\": \"Information\",\n",
    "    \"Child Rights\": \"Information\",\n",
    "    \"Info on Helpline\": \"Information\",\n",
    "    \"Legal Issues\": \"Information\",\n",
    "    \"School Related Issues\": \"Information\", \n",
    "    \"Balanced Diet\": \"Nutrition\",\n",
    "    \"Breastfeeding\": \"Nutrition\",\n",
    "    \"Feeding & Food preparation\": \"Nutrition\",\n",
    "    \"Malnutrition\": \"Nutrition\",\n",
    "    \"Obesity\": \"Nutrition\",\n",
    "    \"Stagnation\": \"Nutrition\",\n",
    "    \"Underweight\": \"Nutrition\",\n",
    "    \"Child Abduction\": \"VANE\",\n",
    "    \"Child Labor\": \"VANE\",\n",
    "    \"Child Marriage\": \"VANE\",\n",
    "    \"Child Neglect\": \"VANE\",\n",
    "    \"Child Trafficking\": \"VANE\",\n",
    "    \"Emotional Abuse\": \"VANE\",\n",
    "    \"Female Genital Mutilation\": \"VANE\",\n",
    "    \"OCSEA\": \"VANE\", \n",
    "    \"Physical Abuse\": \"VANE\",\n",
    "    \"Sexual Abuse\": \"VANE\",\n",
    "    \"Traditional Practice\": \"VANE\",\n",
    "    \"Unlawful Confinement\": \"VANE\",\n",
    "    \"Other\": \"VANE\"  # Final \"Other\" mapping\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde11cc",
   "metadata": {},
   "source": [
    "### 🧪 Dataset mapping and Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0b3db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          category                main_category\n",
      "0               Drug/Alcohol Abuse       Advice and Counselling\n",
      "1                     Homelessness       Advice and Counselling\n",
      "2                         HIV/AIDS       Advice and Counselling\n",
      "3  Relationships (Student/Teacher)       Advice and Counselling\n",
      "4                      Foster Care  Child Maintenance & Custody\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create new column using the mapping dictionary\n",
    "df['main_category'] = df['category'].map(sub_to_main_mapping)\n",
    "\n",
    "# Handle unmapped categories (if any)\n",
    "df['main_category'] = df['main_category'].fillna('Unknown')\n",
    "\n",
    "# Preprocess labels\n",
    "main_categories = sorted(df['main_category'].unique())\n",
    "sub_categories = sorted(df['category'].unique())\n",
    "interventions = sorted(df['intervention'].unique())\n",
    "priorities = [1, 2, 3]\n",
    "\n",
    "print(df[['category', 'main_category']].head())\n",
    "logger.info(df[['category', 'main_category']].head())\n",
    "\n",
    "\n",
    "# Create mappings\n",
    "main_cat2id = {cat: i for i, cat in enumerate(main_categories)}\n",
    "sub_cat2id = {cat: i for i, cat in enumerate(sub_categories)}\n",
    "interv2id = {interv: i for i, interv in enumerate(interventions)}\n",
    "priority2id = {p: i for i, p in enumerate(priorities)}\n",
    "\n",
    "# Apply mappings\n",
    "df['main_category_id'] = df['main_category'].map(main_cat2id)\n",
    "df['sub_category_id'] = df['category'].map(sub_cat2id)\n",
    "df['intervention_id'] = df['intervention'].map(interv2id)\n",
    "df['priority_id'] = df['priority'].map(lambda x: priority2id[x])\n",
    "df['text'] = df['narrative']\n",
    "\n",
    "# Split dataset\n",
    "train_df, test_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.1, \n",
    "    random_state=42,\n",
    "    stratify=df['sub_category_id']\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'main_category_id', 'sub_category_id', 'intervention_id', 'priority_id']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'main_category_id', 'sub_category_id', 'intervention_id', 'priority_id']])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validation\": test_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05994f19",
   "metadata": {},
   "source": [
    "### Model Head and Layers Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b90ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8810, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36dfaea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c15d3736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf44a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class MultiTaskDistilBert(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, num_main, num_sub, num_interv, num_priority):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        self.classifier_main = nn.Linear(config.dim, num_main)\n",
    "        self.classifier_sub = nn.Linear(config.dim, num_sub)\n",
    "        self.classifier_interv = nn.Linear(config.dim, num_interv)\n",
    "        self.classifier_priority = nn.Linear(config.dim, num_priority)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, \n",
    "                main_category_id=None, sub_category_id=None, \n",
    "                intervention_id=None, priority_id=None):\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        hidden_state = distilbert_output.last_hidden_state \n",
    "        pooled_output = hidden_state[:, 0]                 \n",
    "        pooled_output = self.pre_classifier(pooled_output) \n",
    "  \n",
    "        pooled_output = nn.ReLU()(pooled_output)           \n",
    "        pooled_output = self.dropout(pooled_output)        \n",
    "        \n",
    "        logits_main = self.classifier_main(pooled_output)\n",
    "        logits_sub = self.classifier_sub(pooled_output)\n",
    "        logits_interv = self.classifier_interv(pooled_output)\n",
    "        logits_priority = self.classifier_priority(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if main_category_id is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss_main = loss_fct(logits_main, main_category_id)\n",
    "            loss_sub = loss_fct(logits_sub, sub_category_id)\n",
    "            loss_interv = loss_fct(logits_interv, intervention_id)\n",
    "            loss_priority = loss_fct(logits_priority, priority_id)\n",
    "            loss = loss_main + loss_sub + loss_interv + loss_priority\n",
    "        \n",
    "        if loss is not None:\n",
    "            return (loss, logits_main, logits_sub, logits_interv, logits_priority)\n",
    "        else:\n",
    "            return (logits_main, logits_sub, logits_interv, logits_priority)\n",
    "\n",
    "    \n",
    "    def get_embeddings(self, input_ids, attention_mask):\n",
    "        return self.forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )[-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86dafa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': 'v-1', 'date_trained': '2025-08-25 16:05:13.705971', 'eval_avg_acc': 0.6580694586312563, 'last_best_model_dir': 'multitask_distilbert_v-1', 'metrics': {'eval_avg_acc': 0.6580694586312563, 'eval_avg_precision': 0.6411514284441623, 'eval_avg_recall': 0.6580694586312563, 'eval_avg_f1': 0.6413574307508194, 'eval_main_acc': 0.7099080694586313, 'eval_main_precision': 0.708739077146966, 'eval_main_recall': 0.7099080694586313, 'eval_main_f1': 0.704318734141012, 'eval_sub_acc': 0.5822267620020429, 'eval_sub_precision': 0.5812330008069666, 'eval_sub_recall': 0.5822267620020429, 'eval_sub_f1': 0.572191139569792, 'eval_interv_acc': 0.6700715015321757, 'eval_interv_precision': 0.6514564843754779, 'eval_interv_recall': 0.6700715015321757, 'eval_interv_f1': 0.6554767410743746, 'eval_priority_acc': 0.6700715015321757, 'eval_priority_precision': 0.6231771514472384, 'eval_priority_recall': 0.6700715015321757, 'eval_priority_f1': 0.6334431082180993, 'eval_runtime': 7.581, 'eval_samples_per_second': 129.138, 'eval_steps_per_second': 8.178, 'epoch': 12.0}}\n",
      "/home/rogendo/chl_scratch/multitask_distilbert_version/multitask_distilbert_v-1\n",
      "Loading existing model from /home/rogendo/chl_scratch/multitask_distilbert_version/multitask_distilbert_v-1 for continuous fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ____ continuous fine-tuning and version control ____\n",
    "\n",
    "# paths and loading existing metadata\n",
    "model_output_dir = \"/home/rogendo/chl_scratch/multitask_distilbert_version\"\n",
    "metadata_file = os.path.join(model_output_dir, \"model_metadata.json\")\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "# Load metadata of the last best model\n",
    "if os.path.exists(metadata_file):\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        print(metadata)\n",
    "        logger.info(f\"Model Version Metadata {metadata}\")\n",
    "\n",
    "    last_best_model_path = os.path.join(model_output_dir, metadata['last_best_model_dir'])\n",
    "    print(last_best_model_path)\n",
    "    print(f\"Loading existing model from {last_best_model_path} for continuous fine-tuning.\")\n",
    "    logger.info(f\"Loading existing model from {last_best_model_path} for continuous fine-tuning.\")\n",
    "   \n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(last_best_model_path):\n",
    "        model = MultiTaskDistilBert.from_pretrained(\n",
    "            last_best_model_path,\n",
    "            num_main=len(main_categories),\n",
    "            num_sub=len(sub_categories),\n",
    "            num_interv=len(interventions),\n",
    "            num_priority=len(priorities)\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(last_best_model_path)\n",
    "    else:\n",
    "        # Fallback to base model if last best model directory is missing\n",
    "        print(f\"Warning: Last best model directory not found. Starting from base checkpoint.\")\n",
    "        logger.warning (f\"Warning: Last best model directory not found. Starting from base checkpoint.\")\n",
    "\n",
    "        checkpoint = \"distilbert-base-uncased\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        model = MultiTaskDistilBert.from_pretrained(\n",
    "            checkpoint,\n",
    "            num_main=len(main_categories),\n",
    "            num_sub=len(sub_categories),\n",
    "            num_interv=len(interventions),\n",
    "            num_priority=len(priorities)\n",
    "        )\n",
    "else:\n",
    "    logger.info(\"No existing model found. Starting from base checkpoint.\")\n",
    "    checkpoint = \"distilbert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    model = MultiTaskDistilBert.from_pretrained(\n",
    "        checkpoint,\n",
    "        num_main=len(main_categories),\n",
    "        num_sub=len(sub_categories),\n",
    "        num_interv=len(interventions),\n",
    "        num_priority=len(priorities)\n",
    "    )\n",
    "\n",
    "# --- End  continuous fine-tuning and version control ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2260b2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████| 8810/8810 [00:00<00:00, 9361.09 examples/s]\n",
      "Map: 100%|███████████████████████████| 979/979 [00:00<00:00, 9649.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(batch):\n",
    "    encoding = tokenizer(\n",
    "        batch[\"text\"], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    return encoding\n",
    "\n",
    "# Apply tokenization\n",
    "encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
    "encoded_dataset.set_format(\"torch\", columns=[\n",
    "    \"input_ids\", \"attention_mask\", \n",
    "    \"main_category_id\", \"sub_category_id\", \n",
    "    \"intervention_id\", \"priority_id\"\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6a33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    logger.info(\"compute_metrics called\")\n",
    "    # p.predictions is a tuple of logits for each task\n",
    "    # p.label_ids is a tuple of true labels for each task\n",
    "\n",
    "    logits_main, logits_sub, logits_interv, logits_priority = p.predictions\n",
    "    labels_main, labels_sub, labels_interv, labels_priority = p.label_ids\n",
    "\n",
    "    preds_main = np.argmax(logits_main, axis=1)\n",
    "    preds_sub = np.argmax(logits_sub, axis=1)\n",
    "    preds_interv = np.argmax(logits_interv, axis=1)\n",
    "    preds_priority = np.argmax(logits_priority, axis=1)\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Helper function to compute and add metrics for each task\n",
    "    def add_task_metrics(task_name, labels, preds):\n",
    "        accuracy = accuracy_score(labels, preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        metrics[f\"{task_name}_acc\"] = accuracy\n",
    "        metrics[f\"{task_name}_precision\"] = precision\n",
    "        metrics[f\"{task_name}_recall\"] = recall\n",
    "        metrics[f\"{task_name}_f1\"] = f1\n",
    "\n",
    "    add_task_metrics(\"main\", labels_main, preds_main)\n",
    "    add_task_metrics(\"sub\", labels_sub, preds_sub)\n",
    "    add_task_metrics(\"interv\", labels_interv, preds_interv)\n",
    "    add_task_metrics(\"priority\", labels_priority, preds_priority)\n",
    "\n",
    "    # Calculate average metrics across all tasks\n",
    "    avg_acc = np.mean([metrics[f\"{task}_acc\"] for task in [\"main\", \"sub\", \"interv\", \"priority\"]])\n",
    "    avg_precision = np.mean([metrics[f\"{task}_precision\"] for task in [\"main\", \"sub\", \"interv\", \"priority\"]])\n",
    "    avg_recall = np.mean([metrics[f\"{task}_recall\"] for task in [\"main\", \"sub\", \"interv\", \"priority\"]])\n",
    "    avg_f1 = np.mean([metrics[f\"{task}_f1\"] for task in [\"main\", \"sub\", \"interv\", \"priority\"]])\n",
    "\n",
    "    metrics[\"eval_avg_acc\"] = avg_acc\n",
    "    metrics[\"eval_avg_precision\"] = avg_precision\n",
    "    metrics[\"eval_avg_recall\"] = avg_recall\n",
    "    metrics[\"eval_avg_f1\"] = avg_f1\n",
    "\n",
    "    return metrics\n",
    "\n",
    "class MultiTaskTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = {\n",
    "            \"main_category_id\": inputs.pop(\"main_category_id\"),\n",
    "            \"sub_category_id\": inputs.pop(\"sub_category_id\"),\n",
    "            \"intervention_id\": inputs.pop(\"intervention_id\"),\n",
    "            \"priority_id\": inputs.pop(\"priority_id\")\n",
    "        }\n",
    "        outputs = model(**inputs, **labels)\n",
    "        # outputs is a tuple: (loss, logits_main, logits_sub, logits_interv, logits_priority)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        if return_outputs:\n",
    "            return (loss, *outputs[1:])\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only=False, ignore_keys=None):\n",
    "        # Remove labels from inputs\n",
    "        label_keys = [\"main_category_id\", \"sub_category_id\", \"intervention_id\", \"priority_id\"]\n",
    "        labels = {key: inputs.pop(key) for key in label_keys if key in inputs}\n",
    "\n",
    "        # Forward pass without labels\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Extract logits (assumes model returns tuple: (logits_main, logits_sub, ...)) if no loss is returned\n",
    "        # Or (loss, logits_main, logits_sub, ...) if loss is returned\n",
    "        \n",
    "        # Check if the first element is a tensor (likely loss)\n",
    "        if isinstance(outputs[0], torch.Tensor) and outputs[0].dim() == 0: # Check if it's a scalar tensor\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1:] # Skip loss\n",
    "        else:\n",
    "            loss = None\n",
    "            logits = outputs # All elements are logits\n",
    "\n",
    "        # Handle label presence\n",
    "        \n",
    "        if labels:\n",
    "            label_values = (labels[\"main_category_id\"], labels[\"sub_category_id\"],\n",
    "                           labels[\"intervention_id\"], labels[\"priority_id\"])\n",
    "        \n",
    "        return (loss, logits, label_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5152ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7714' max='7714' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7714/7714 40:57, Epoch 14/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Avg Acc</th>\n",
       "      <th>Avg Precision</th>\n",
       "      <th>Avg Recall</th>\n",
       "      <th>Avg F1</th>\n",
       "      <th>Main Acc</th>\n",
       "      <th>Main Precision</th>\n",
       "      <th>Main Recall</th>\n",
       "      <th>Main F1</th>\n",
       "      <th>Sub Acc</th>\n",
       "      <th>Sub Precision</th>\n",
       "      <th>Sub Recall</th>\n",
       "      <th>Sub F1</th>\n",
       "      <th>Interv Acc</th>\n",
       "      <th>Interv Precision</th>\n",
       "      <th>Interv Recall</th>\n",
       "      <th>Interv F1</th>\n",
       "      <th>Priority Acc</th>\n",
       "      <th>Priority Precision</th>\n",
       "      <th>Priority Recall</th>\n",
       "      <th>Priority F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.827200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.652962</td>\n",
       "      <td>0.642867</td>\n",
       "      <td>0.652962</td>\n",
       "      <td>0.638604</td>\n",
       "      <td>0.698672</td>\n",
       "      <td>0.691734</td>\n",
       "      <td>0.698672</td>\n",
       "      <td>0.693446</td>\n",
       "      <td>0.585291</td>\n",
       "      <td>0.602546</td>\n",
       "      <td>0.585291</td>\n",
       "      <td>0.582497</td>\n",
       "      <td>0.669050</td>\n",
       "      <td>0.644297</td>\n",
       "      <td>0.669050</td>\n",
       "      <td>0.648527</td>\n",
       "      <td>0.658836</td>\n",
       "      <td>0.632892</td>\n",
       "      <td>0.658836</td>\n",
       "      <td>0.629946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.479400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.655005</td>\n",
       "      <td>0.640197</td>\n",
       "      <td>0.655005</td>\n",
       "      <td>0.636332</td>\n",
       "      <td>0.699694</td>\n",
       "      <td>0.701763</td>\n",
       "      <td>0.699694</td>\n",
       "      <td>0.689314</td>\n",
       "      <td>0.576098</td>\n",
       "      <td>0.587158</td>\n",
       "      <td>0.576098</td>\n",
       "      <td>0.569818</td>\n",
       "      <td>0.673136</td>\n",
       "      <td>0.649992</td>\n",
       "      <td>0.673136</td>\n",
       "      <td>0.656432</td>\n",
       "      <td>0.671093</td>\n",
       "      <td>0.621876</td>\n",
       "      <td>0.671093</td>\n",
       "      <td>0.629766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.142900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.648876</td>\n",
       "      <td>0.652724</td>\n",
       "      <td>0.648876</td>\n",
       "      <td>0.639178</td>\n",
       "      <td>0.716037</td>\n",
       "      <td>0.724539</td>\n",
       "      <td>0.716037</td>\n",
       "      <td>0.701643</td>\n",
       "      <td>0.591420</td>\n",
       "      <td>0.615874</td>\n",
       "      <td>0.591420</td>\n",
       "      <td>0.588733</td>\n",
       "      <td>0.641471</td>\n",
       "      <td>0.651712</td>\n",
       "      <td>0.641471</td>\n",
       "      <td>0.638995</td>\n",
       "      <td>0.646578</td>\n",
       "      <td>0.618770</td>\n",
       "      <td>0.646578</td>\n",
       "      <td>0.627341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.866300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.637984</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.633717</td>\n",
       "      <td>0.703779</td>\n",
       "      <td>0.699264</td>\n",
       "      <td>0.703779</td>\n",
       "      <td>0.690296</td>\n",
       "      <td>0.576098</td>\n",
       "      <td>0.599292</td>\n",
       "      <td>0.576098</td>\n",
       "      <td>0.575315</td>\n",
       "      <td>0.658836</td>\n",
       "      <td>0.641738</td>\n",
       "      <td>0.658836</td>\n",
       "      <td>0.648005</td>\n",
       "      <td>0.668029</td>\n",
       "      <td>0.611640</td>\n",
       "      <td>0.668029</td>\n",
       "      <td>0.621251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.576900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.645046</td>\n",
       "      <td>0.648603</td>\n",
       "      <td>0.645046</td>\n",
       "      <td>0.641926</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.719597</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.712287</td>\n",
       "      <td>0.590398</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.590398</td>\n",
       "      <td>0.591516</td>\n",
       "      <td>0.650664</td>\n",
       "      <td>0.649250</td>\n",
       "      <td>0.650664</td>\n",
       "      <td>0.647611</td>\n",
       "      <td>0.620020</td>\n",
       "      <td>0.615395</td>\n",
       "      <td>0.620020</td>\n",
       "      <td>0.616288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.423600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.641726</td>\n",
       "      <td>0.644549</td>\n",
       "      <td>0.641726</td>\n",
       "      <td>0.638836</td>\n",
       "      <td>0.701736</td>\n",
       "      <td>0.700706</td>\n",
       "      <td>0.701736</td>\n",
       "      <td>0.697412</td>\n",
       "      <td>0.586313</td>\n",
       "      <td>0.610671</td>\n",
       "      <td>0.586313</td>\n",
       "      <td>0.589291</td>\n",
       "      <td>0.648621</td>\n",
       "      <td>0.649969</td>\n",
       "      <td>0.648621</td>\n",
       "      <td>0.646641</td>\n",
       "      <td>0.630235</td>\n",
       "      <td>0.616851</td>\n",
       "      <td>0.630235</td>\n",
       "      <td>0.622001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.199900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.639428</td>\n",
       "      <td>0.642328</td>\n",
       "      <td>0.639428</td>\n",
       "      <td>0.637878</td>\n",
       "      <td>0.709908</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.709908</td>\n",
       "      <td>0.706802</td>\n",
       "      <td>0.582227</td>\n",
       "      <td>0.609641</td>\n",
       "      <td>0.582227</td>\n",
       "      <td>0.587464</td>\n",
       "      <td>0.650664</td>\n",
       "      <td>0.639958</td>\n",
       "      <td>0.650664</td>\n",
       "      <td>0.643832</td>\n",
       "      <td>0.614913</td>\n",
       "      <td>0.612607</td>\n",
       "      <td>0.614913</td>\n",
       "      <td>0.613414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.110500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.641726</td>\n",
       "      <td>0.634192</td>\n",
       "      <td>0.641726</td>\n",
       "      <td>0.634763</td>\n",
       "      <td>0.701736</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.701736</td>\n",
       "      <td>0.698805</td>\n",
       "      <td>0.583248</td>\n",
       "      <td>0.603228</td>\n",
       "      <td>0.583248</td>\n",
       "      <td>0.586228</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.635225</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.643239</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.600429</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.610780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.961400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.644791</td>\n",
       "      <td>0.644514</td>\n",
       "      <td>0.644791</td>\n",
       "      <td>0.639415</td>\n",
       "      <td>0.706844</td>\n",
       "      <td>0.702342</td>\n",
       "      <td>0.706844</td>\n",
       "      <td>0.698055</td>\n",
       "      <td>0.586313</td>\n",
       "      <td>0.608937</td>\n",
       "      <td>0.586313</td>\n",
       "      <td>0.586910</td>\n",
       "      <td>0.645557</td>\n",
       "      <td>0.639757</td>\n",
       "      <td>0.645557</td>\n",
       "      <td>0.640212</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.627022</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.632483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.652196</td>\n",
       "      <td>0.646083</td>\n",
       "      <td>0.652196</td>\n",
       "      <td>0.644907</td>\n",
       "      <td>0.709908</td>\n",
       "      <td>0.707950</td>\n",
       "      <td>0.709908</td>\n",
       "      <td>0.705328</td>\n",
       "      <td>0.585291</td>\n",
       "      <td>0.611680</td>\n",
       "      <td>0.585291</td>\n",
       "      <td>0.590509</td>\n",
       "      <td>0.665986</td>\n",
       "      <td>0.647663</td>\n",
       "      <td>0.665986</td>\n",
       "      <td>0.655833</td>\n",
       "      <td>0.647600</td>\n",
       "      <td>0.617040</td>\n",
       "      <td>0.647600</td>\n",
       "      <td>0.627958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.787400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.646578</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.646578</td>\n",
       "      <td>0.638709</td>\n",
       "      <td>0.713994</td>\n",
       "      <td>0.711005</td>\n",
       "      <td>0.713994</td>\n",
       "      <td>0.707786</td>\n",
       "      <td>0.580184</td>\n",
       "      <td>0.609892</td>\n",
       "      <td>0.580184</td>\n",
       "      <td>0.586528</td>\n",
       "      <td>0.646578</td>\n",
       "      <td>0.636634</td>\n",
       "      <td>0.646578</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.645557</td>\n",
       "      <td>0.606574</td>\n",
       "      <td>0.645557</td>\n",
       "      <td>0.620026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.661600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.639939</td>\n",
       "      <td>0.646431</td>\n",
       "      <td>0.639939</td>\n",
       "      <td>0.639999</td>\n",
       "      <td>0.716037</td>\n",
       "      <td>0.716484</td>\n",
       "      <td>0.716037</td>\n",
       "      <td>0.714136</td>\n",
       "      <td>0.590398</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>0.590398</td>\n",
       "      <td>0.597551</td>\n",
       "      <td>0.637385</td>\n",
       "      <td>0.632992</td>\n",
       "      <td>0.637385</td>\n",
       "      <td>0.633565</td>\n",
       "      <td>0.615935</td>\n",
       "      <td>0.613790</td>\n",
       "      <td>0.615935</td>\n",
       "      <td>0.614743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.642748</td>\n",
       "      <td>0.643095</td>\n",
       "      <td>0.642748</td>\n",
       "      <td>0.638210</td>\n",
       "      <td>0.718080</td>\n",
       "      <td>0.717066</td>\n",
       "      <td>0.718080</td>\n",
       "      <td>0.712623</td>\n",
       "      <td>0.588355</td>\n",
       "      <td>0.620901</td>\n",
       "      <td>0.588355</td>\n",
       "      <td>0.595025</td>\n",
       "      <td>0.628192</td>\n",
       "      <td>0.622939</td>\n",
       "      <td>0.628192</td>\n",
       "      <td>0.624715</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.611475</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.620477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.604600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.644025</td>\n",
       "      <td>0.642605</td>\n",
       "      <td>0.644025</td>\n",
       "      <td>0.640179</td>\n",
       "      <td>0.713994</td>\n",
       "      <td>0.711736</td>\n",
       "      <td>0.713994</td>\n",
       "      <td>0.710316</td>\n",
       "      <td>0.585291</td>\n",
       "      <td>0.611746</td>\n",
       "      <td>0.585291</td>\n",
       "      <td>0.591576</td>\n",
       "      <td>0.638407</td>\n",
       "      <td>0.631069</td>\n",
       "      <td>0.638407</td>\n",
       "      <td>0.633648</td>\n",
       "      <td>0.638407</td>\n",
       "      <td>0.615870</td>\n",
       "      <td>0.638407</td>\n",
       "      <td>0.625176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run trainer_output at: http://192.168.8.18:5000/#/experiments/13/runs/bc052dc155a04092916f04a4be53a668\n",
      "🧪 View experiment at: http://192.168.8.18:5000/#/experiments/13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 09:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    # output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=14,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_avg_acc\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "logger.info(len(encoded_dataset[\"test\"]))\n",
    "logger.info(len(encoded_dataset[\"train\"]))\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = MultiTaskTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(\"CHS_tz_classifier_distilbert\")\n",
    "tokenizer.save_pretrained(\"CHS_tz_classifier_distilbert\")\n",
    " \n",
    "\n",
    "# Evaluate the model after training\n",
    "new_metrics = trainer.evaluate(encoded_dataset[\"test\"])\n",
    "new_avg_acc = new_metrics.get('eval_avg_acc', 0)\n",
    "\n",
    "logger.info(f\"Model Performance results: {new_metrics}\")\n",
    "\n",
    "# Load previous best model's average accuracy\n",
    "if os.path.exists(metadata_file):\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    prev_avg_acc = metadata.get('eval_avg_acc', 0)\n",
    "else:\n",
    "    prev_avg_acc = -1\n",
    "\n",
    "# Check if the new model is better\n",
    "if new_avg_acc > prev_avg_acc:\n",
    "    logger.info(\" New model performance improved! Saving new version.\")\n",
    "    # Create new version directory\n",
    "    version = len(os.listdir(model_output_dir)) -1\n",
    "    new_model_dir = f\"CHS_tz_classifier_distilbert{version}\"\n",
    "    new_model_path = os.path.join(model_output_dir, new_model_dir)\n",
    "\n",
    "    # Save the model and tokenizer in the new version directory\n",
    "    trainer.save_model(new_model_path)\n",
    "    tokenizer.save_pretrained(new_model_path)\n",
    "\n",
    "    # Update metadata file\n",
    "    metadata = {\n",
    "        \"version\": f\"v{version}\",\n",
    "        \"date_trained\": str(datetime.datetime.now()),\n",
    "        \"eval_avg_acc\": new_avg_acc,\n",
    "        \"last_best_model_dir\": new_model_dir,\n",
    "        \"metrics\": new_metrics\n",
    "    }\n",
    "    with open(metadata_file, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "else:\n",
    "    logger.info(\"Model performance did not improve. Not saving a new version.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "493f1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate and save category embeddings\n",
    "def generate_category_embeddings(categories, model, tokenizer, device):\n",
    "    embeddings = []\n",
    "    for category in categories:\n",
    "        inputs = tokenizer(\n",
    "            category, \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=256, \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            emb = model.get_embeddings(**inputs).cpu().numpy()\n",
    "        embeddings.append(emb[0])\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate embeddings for all categories\n",
    "main_cat_embeddings = generate_category_embeddings(main_categories, model, tokenizer, device)\n",
    "sub_cat_embeddings = generate_category_embeddings(sub_categories, model, tokenizer, device)\n",
    "\n",
    "# Save embeddings\n",
    "os.makedirs(\"embeddings\", exist_ok=True)\n",
    "np.save(\"embeddings/main_cat_embeddings.npy\", main_cat_embeddings)\n",
    "np.save(\"embeddings/sub_cat_embeddings.npy\", sub_cat_embeddings)\n",
    "\n",
    "# Save category lists\n",
    "with open(\"main_categories.json\", \"w\") as f:\n",
    "    json.dump(main_categories, f)\n",
    "with open(\"sub_categories.json\", \"w\") as f:\n",
    "    json.dump(sub_categories, f)\n",
    "with open(\"interventions.json\", \"w\") as f:\n",
    "    json.dump(interventions, f)\n",
    "with open(\"priorities.json\", \"w\") as f:\n",
    "    json.dump(priorities, f)\n",
    "\n",
    "# Evaluation\n",
    "metrics = trainer.evaluate(encoded_dataset[\"test\"])\n",
    "logger.info(f\"Model Performance results: {metrics}\")\n",
    "\n",
    "# Save metrics\n",
    "with open(\"multilabel_model_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "logger.info(\" Model performance on test set:\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9ef65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c1e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a78d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'main_category_id', 'sub_category_id', 'intervention_id', 'priority_id', '__index_level_0__'],\n",
      "    num_rows: 979\n",
      "})\n",
      "Saved confusion_matrices/main_category.png\n",
      "Saved confusion_matrices/sub_category.png\n",
      "Saved confusion_matrices/intervention.png\n",
      "Saved confusion_matrices/priority.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT: Main Category\n",
      "============================================================\n",
      "Classes present in test data: 8/8\n",
      "\n",
      "Performance on present classes:\n",
      "Class                           Precision     Recall         F1    Support\n",
      "Advice and Counselling              0.613      0.763      0.680        299\n",
      "Child Maintenance & Custody         0.617      0.804      0.698         92\n",
      "Disability                          0.948      0.880      0.913        125\n",
      "GBV                                 0.603      0.471      0.529         87\n",
      "Information                         0.299      0.282      0.290         71\n",
      "Nutrition                           0.925      0.843      0.882        102\n",
      "Unknown                             1.000      0.083      0.154         12\n",
      "VANE                                0.718      0.534      0.613        191\n",
      "\n",
      "Overall Accuracy: 0.676\n",
      "Macro Avg F1: 0.595\n",
      "Weighted Avg F1: 0.671\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT: Sub Category\n",
      "============================================================\n",
      "Classes present in test data: 66/66\n",
      "\n",
      "Performance on present classes:\n",
      "Class                           Precision     Recall         F1    Support\n",
      "Adoption                            0.647      0.647      0.647         17\n",
      "Albinism                            1.000      1.000      1.000         16\n",
      "Balanced Diet                       0.833      1.000      0.909         15\n",
      "Birth Registration                  1.000      0.929      0.963         14\n",
      "Breastfeeding                       1.000      0.857      0.923         14\n",
      "Bullying                            0.524      0.733      0.611         15\n",
      "Child Abduction                     0.769      0.625      0.690         16\n",
      "Child Abuse                         0.000      0.000      0.000         14\n",
      "Child Labor                         0.923      0.857      0.889         14\n",
      "Child Marriage                      0.846      0.688      0.759         16\n",
      "Child Neglect                       0.600      0.600      0.600         15\n",
      "Child Rights                        0.333      0.133      0.190         15\n",
      "Child Trafficking                   0.636      0.438      0.519         16\n",
      "Child in Conflict with the Law      0.364      0.571      0.444         14\n",
      "Custody                             0.154      0.267      0.195         15\n",
      "Discrimination                      0.857      0.857      0.857         14\n",
      "Drug/Alcohol Abuse                  0.812      0.929      0.867         14\n",
      "Emotional Abuse                     0.667      0.500      0.571         12\n",
      "Emotional/Psychological Violence      0.250      0.429      0.316         14\n",
      "Family Relationship                 0.000      0.000      0.000         16\n",
      "Feeding & Food preparation          0.786      0.846      0.815         13\n",
      "Female Genital Mutilation           0.900      0.643      0.750         14\n",
      "Financial/Economic Violence         0.882      0.938      0.909         16\n",
      "Forced Marriage Violence            0.714      0.714      0.714         14\n",
      "Foster Care                         0.417      0.625      0.500         16\n",
      "HIV/AIDS                            1.000      0.929      0.963         14\n",
      "Harmful Practice                    0.500      0.154      0.235         13\n",
      "Hearing impairment                  1.000      1.000      1.000         15\n",
      "Homelessness                        0.667      0.769      0.714         13\n",
      "Hydrocephalus                       0.929      0.929      0.929         14\n",
      "Info on Helpline                    0.333      0.438      0.378         16\n",
      "Legal Issues                        0.000      0.000      0.000         13\n",
      "Legal issues                        0.154      0.125      0.138         16\n",
      "Maintenance                         0.667      0.500      0.571         16\n",
      "Malnutrition                        0.583      0.500      0.538         14\n",
      "Missing Child                       0.556      0.667      0.606         15\n",
      "Multiple disabilities               1.000      0.938      0.968         16\n",
      "No Care Giver                       0.500      0.786      0.611         14\n",
      "OCSEA                               0.000      0.000      0.000         15\n",
      "Obesity                             1.000      0.938      0.968         16\n",
      "Other                               0.083      0.071      0.077         14\n",
      "Outside Mandate                     0.100      0.083      0.091         12\n",
      "Peer Relationships                  0.417      0.333      0.370         15\n",
      "Physical Abuse                      0.269      0.438      0.333         16\n",
      "Physical Health                     0.154      0.353      0.214         17\n",
      "Physical Violence                   0.000      0.000      0.000         14\n",
      "Physical impairment                 0.571      0.250      0.348         16\n",
      "Psychosocial/Mental Health          0.261      0.429      0.324         14\n",
      "Relationships (Boy/Girl)            0.091      0.067      0.077         15\n",
      "Relationships (Parent/Child)        0.111      0.176      0.136         17\n",
      "Relationships (Student/Teacher)      0.333      0.133      0.190         15\n",
      "School Related Issues               0.400      0.615      0.485         13\n",
      "School related issues               0.357      0.357      0.357         14\n",
      "Self Esteem                         0.231      0.231      0.231         13\n",
      "Sexual & Reproductive Health        0.241      0.412      0.304         17\n",
      "Sexual Abuse                        0.250      0.200      0.222         15\n",
      "Sexual Violence                     0.455      0.312      0.370         16\n",
      "Speech impairment                   0.882      0.938      0.909         16\n",
      "Spinal bifida                       1.000      1.000      1.000         15\n",
      "Stagnation                          0.250      0.308      0.276         13\n",
      "Student/ Teacher Relationship       0.286      0.133      0.182         15\n",
      "Teen Pregnancy                      1.000      0.812      0.897         16\n",
      "Traditional Practice                0.867      0.929      0.897         14\n",
      "Underweight                         0.857      0.706      0.774         17\n",
      "Unlawful Confinement                0.600      0.429      0.500         14\n",
      "Visual impairment                   0.941      0.941      0.941         17\n",
      "\n",
      "Overall Accuracy: 0.535\n",
      "Macro Avg F1: 0.527\n",
      "Weighted Avg F1: 0.529\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT: Intervention\n",
      "============================================================\n",
      "Classes present in test data: 4/4\n",
      "\n",
      "Performance on present classes:\n",
      "Class                           Precision     Recall         F1    Support\n",
      "Awareness/Information Provided      0.000      0.000      0.000         10\n",
      "Counselling                         0.686      0.806      0.741        588\n",
      "Referral                            0.548      0.441      0.489        347\n",
      "Signposting                         0.111      0.029      0.047         34\n",
      "\n",
      "Overall Accuracy: 0.641\n",
      "Macro Avg F1: 0.319\n",
      "Weighted Avg F1: 0.620\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT: Priority\n",
      "============================================================\n",
      "Classes present in test data: 3/3\n",
      "\n",
      "Performance on present classes:\n",
      "Class                           Precision     Recall         F1    Support\n",
      "1                                   0.336      0.237      0.278        152\n",
      "2                                   0.747      0.803      0.774        654\n",
      "3                                   0.391      0.382      0.386        173\n",
      "\n",
      "Overall Accuracy: 0.640\n",
      "Macro Avg F1: 0.479\n",
      "Weighted Avg F1: 0.628\n",
      "\n",
      "============================================================\n",
      "ADDITIONAL ANALYSIS\n",
      "============================================================\n",
      "Test samples: 979\n",
      "Main categories in test data: {'Child Maintenance & Custody', 'GBV', 'Disability', 'Nutrition', 'Information', 'Advice and Counselling', 'Unknown', 'VANE'}\n",
      "Main categories not in test data: set()\n",
      "\n",
      "Task                   Accuracy   Correct/Total\n",
      "Main Category            67.62%         662/979\n",
      "Sub Category             53.52%         524/979\n",
      "Intervention             64.15%         628/979\n",
      "Priority                 64.04%         627/979\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load trained model\n",
    "# model_path = '/opt/chl_ai/models/raw-models/ai_models/MultiClassifier/multitask_distilbert'\n",
    "model_path = \"/home/rogendo/Work/ai/ai_service/qa_distilbert_v2\"\n",
    "# model_path = new_model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = MultiTaskDistilBert.from_pretrained(\n",
    "    model_path,\n",
    "    num_main=len(main_categories),\n",
    "    num_sub=len(sub_categories),\n",
    "    num_interv=len(interventions),\n",
    "    num_priority=len(priorities)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "\n",
    "def classify_multitask_case_return_indices(narrative):\n",
    "    text = narrative.lower().strip()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits_main, logits_sub, logits_interv, logits_priority = outputs\n",
    "        preds_main = torch.argmax(logits_main, dim=1).cpu().numpy()[0]\n",
    "        preds_sub = torch.argmax(logits_sub, dim=1).cpu().numpy()[0]\n",
    "        preds_interv = torch.argmax(logits_interv, dim=1).cpu().numpy()[0]\n",
    "        preds_priority = torch.argmax(logits_priority, dim=1).cpu().numpy()[0]\n",
    "    \n",
    "    return preds_main, preds_sub, preds_interv, preds_priority\n",
    "\n",
    "# test_data = [\n",
    "#     {\n",
    "#         \"narrative\": \"On <DATE_TIME>, a girl <PERSON> (<DATE_TIME> ) from <LOCATION> district reported being mistreated and verbally abused by their caregiver. She reported that it has been negatively affected and her esteem has gone down and she feels unsafe staying at her home. She requested for adoption as it was proving difficult to stay with the caregiver, who was not related to her and did not love her. The counselor advised her to be patient and that her issue has been filed and will be followed up. Sheee was glad for the counselor help\",\n",
    "#         \"main_category\": \"VANE\",\n",
    "#         \"sub_category\": \"Emotional Abuse\",\n",
    "#         \"intervention\": \"Counselling\",\n",
    "#         \"priority\": 2\n",
    "#     },\n",
    "#     {\n",
    "#         \"narrative\": \"On 04 November 2022 Mustafa Ahmadi called on 116 for the purpose of getting an understanding on the meaning of Female Genital Mutilation.A counsellor explained to him that Female Genital Mutilation means the removal of genital parts of the female or woman.The parts removes are clitoris,labia majora or labia minora, FGM has several effects on the victim such as a high rate of bleeding, to acquire infectious diseases such as HIV, psychological problems, and pain. Apart from that Mustafa also asked about the effects of child marriage whereby the counselor explained to him that child marriage has negative effects such as failure to meet the life dreams due to school dropout, failure to make decisions as a female so she will depend on her husband to decide every matter of the family,psychological problems.Mustafa appreciated for the information.\",\n",
    "#         \"main_category\": \"Information\",\n",
    "#         \"sub_category\": \"Child Abuse\",\n",
    "#         \"intervention\": \"Counselling\",\n",
    "#         \"priority\": 1\n",
    "#     },\n",
    "\n",
    "#     {\n",
    "#         \"narrative\": \"On 05 November 2022,Grace John called on 116 for the purpose of getting understanding on the service provided by the child helpline and its jurisdiction. The counsellor explained to her that 116 provides the service of reporting, receiving, referring and recording child abuse cases to the social welfare officers,to provide awareness on child nutrition,parenting and child rights as well as child maintenance.Then Grace said that she is divorced by her husband who does not not have any job,so she wanted to understand the mechanism for him to provide service to the children,a counsellor explained to her that if a father do not have any job then he cannot provide for the children so she should continue to provide for them until the father get a job which will enable him to provide srvices to the children and if he will refuse then she should report him to the social welfare officer so as to force him to do right.Grace appreciated for the information.\",\n",
    "#         \"main_category\": \"Child Maintenance & Custody\",\n",
    "#         \"sub_category\": \"Maintenance\",\n",
    "#         \"intervention\": 'Awareness/Information Provided',\n",
    "#         \"priority\": 2\n",
    "#     },\n",
    "\n",
    "#     {\n",
    "#     \"narrative\": \"On 12 November 2022, the helpline center received a call from Abubaker in Lwandai Village, Soni Ward, Bumbuli District, Tanga Region. He wanted to understand the causes and effects of mental impairment. The counselor explained how biological and physical factors can contribute to the condition, and Abubaker confirmed that he understood the information.\",\n",
    "#     \"main_category\": \"Information\",\n",
    "#     \"sub_category\": \"Psychosocial/Mental Health\",\n",
    "#     \"intervention\": \"Counselling\",\n",
    "#     \"priority\": 2\n",
    "# },\n",
    "\n",
    "# {\n",
    "#     \"narrative\": \"On 12 November 2022, Bahati Ndelesero, 18, from Kibaigwa Village, Kongwa District, Dodoma Region, called the helpline seeking advice on balanced diets as his wife prepares for pregnancy. The counselor advised him to ensure meals include foods from all five main groups — cereals and tubers, animal and plant proteins, fruits, vegetables, and healthy sugars or oils — to support good health for both mother and child.\",\n",
    "#     \"main_category\": \"Nutrition\",\n",
    "#     \"sub_category\": \"Balanced Diet\",\n",
    "#     \"intervention\": \"Awareness/Information Provided\",\n",
    "#     \"priority\": 2\n",
    "# },\n",
    "\n",
    "# {\n",
    "#     \"narrative\": \"On 12 November 2022, Awadhi Shaibu, 27, from Kiangara Village, Liwale District, Lindi Region, reported that his 3-year-old son Yasri had become fearful and withdrawn after his parents separated. The counselor explained that such behavior may signal emotional distress caused by lack of parental bonding and advised both parents to resolve conflicts, provide love, support, and protection, and avoid exposing the child to further tension or abuse.\",\n",
    "#     \"main_category\": \"Advice and Counselling\",\n",
    "#     \"sub_category\": \"Relationships (Parent/Child)\",\n",
    "#     \"intervention\": \"Counselling\",\n",
    "#     \"priority\": 1\n",
    "# },\n",
    "\n",
    "\n",
    "\n",
    "# {\n",
    "#     \"narrative\": \"On 13 November 2022, the helpline received a call from Amina Yusuf, 16, from Mbinga District, Ruvuma Region, reporting that her uncle constantly shouts at her and calls her names. She said this has lowered her confidence and made her afraid to stay at home. The counselor reassured her, documented the case, and explained that follow-up action will be taken.\",\n",
    "#     \"main_category\": \"VANE\",\n",
    "#     \"sub_category\": \"Emotional Abuse\",\n",
    "#     \"intervention\": \"Counselling\",\n",
    "#     \"priority\": 1\n",
    "# },\n",
    "# {\n",
    "#     \"narrative\": \"On 14 November 2022, Daudi Mshana from Handeni District, Tanga Region, called the helpline asking for information on the effects of child labor. The counselor explained that child labor can lead to school dropout, health problems, and long-term poverty. Daudi thanked the counselor for clarifying these issues.\",\n",
    "#     \"main_category\": \"Information\",\n",
    "#     \"sub_category\": \"Child Labor\",\n",
    "#     \"intervention\": \"Counselling\",\n",
    "#     \"priority\": 1\n",
    "# },\n",
    "# {\n",
    "#     \"narrative\": \"On 15 November 2022, the helpline received a call from Salum Mwinyi, 17, in Korogwe District, Tanga Region. He wanted to understand why drug use among youth is harmful. The counselor explained the physical, social, and legal risks involved with abusing drugs, both legal drugs and illegal drugs. The counselor explained in detail about what each of the effects of the drugs and advised Salum not to get herself involveed with any drugs. Salum expressed appreciation for the advice.\",\n",
    "#     \"main_category\": \"Information\",\n",
    "#     \"sub_category\": \"Drug/Alcohol Abuse\",\n",
    "#     \"intervention\": \"Counselling\",\n",
    "#     \"priority\": 2\n",
    "# },\n",
    "\n",
    "# {\n",
    "#     \"narrative\": \"On 16 November 2022, the helpline was contacted by Jafari Said, 25, from Kilombero District, Morogoro Region. He asked how to provide a safe home environment for his two young sisters. The counselor advised him on good parenting practices and protecting them from abuse.\",\n",
    "#     \"main_category\": \"Advice and Counselling\",\n",
    "#     \"sub_category\": \"Relationships (Parent/Child)\",\n",
    "#     \"intervention\": \"Counselling\",\n",
    "#     \"priority\": 2\n",
    "# },\n",
    "\n",
    "# {\n",
    "#     \"narrative\": \"On 17 November 2022, Paulo Samson, 19, from Same District, Kilimanjaro Region, called to ask about healthy food choices for his younger siblings. The counselor gave guidance on including proteins, vegetables, fruits, and whole grains to ensure proper growth and development.\",\n",
    "#     \"main_category\": \"Nutrition\",\n",
    "#     \"sub_category\": 'Balanced Diet',\n",
    "#     \"intervention\": \"Awareness/Information Provided\",\n",
    "#     \"priority\": 3\n",
    "# },\n",
    "# {\n",
    "#     \"narrative\": \"On 18 November 2022, Ramadhan Musa, 28, from Sumbawanga Urban District, Rukwa Region, requested information about birth registration. The counselor explained the registration process, benefits of having a birth certificate, and directed him to the nearest registration office. He appreciated the assistance.\",\n",
    "#     \"main_category\": \"Information\",\n",
    "#     \"sub_category\": \"Child Rights\",\n",
    "#     \"intervention\": \"Awareness/Information Provided\",\n",
    "#     \"priority\": 1\n",
    "# }\n",
    "\n",
    "# ]\n",
    "\n",
    "test_data = dataset['validation']\n",
    "print(test_data)\n",
    "# Collect true and predicted labels\n",
    "true_main, pred_main = [], []\n",
    "true_sub, pred_sub = [], []\n",
    "true_interv, pred_interv = [], []\n",
    "true_priority, pred_priority = [], []\n",
    "\n",
    "for example in test_data:\n",
    "    # Get true indices directly from IDs\n",
    "    true_main.append(example[\"main_category_id\"])\n",
    "    true_sub.append(example[\"sub_category_id\"])\n",
    "    true_interv.append(example[\"intervention_id\"])\n",
    "    \n",
    "    # Append priority_id directly, since it matches the output indices\n",
    "    priority_val = example[\"priority_id\"]\n",
    "    true_priority.append(priority_val)\n",
    "    \n",
    "    # Get predictions\n",
    "    main_idx, sub_idx, interv_idx, priority_idx = classify_multitask_case_return_indices(\n",
    "        example[\"text\"]\n",
    "    )\n",
    "    pred_main.append(main_idx)\n",
    "    pred_sub.append(sub_idx)\n",
    "    pred_interv.append(interv_idx)\n",
    "    pred_priority.append(priority_idx)\n",
    "\n",
    "\n",
    "\n",
    "def plot_enhanced_confusion_matrix(true, pred, classes, title, filename, figsize=(12, 10)):\n",
    "    cm = confusion_matrix(true, pred, labels=range(len(classes)))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, \n",
    "                yticklabels=classes,\n",
    "                cbar_kws={'shrink': 0.8})\n",
    "    plt.title(f'Confusion Matrix - {title}', fontsize=16, pad=20)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.yticks(rotation=0, fontsize=10)\n",
    "\n",
    "    #  accuracy \n",
    "    accuracy = np.trace(cm) / np.sum(cm) if np.sum(cm) > 0 else 0\n",
    "    plt.figtext(0.5, 0.01, f'Accuracy: {accuracy:.2%}', ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved {filename}\")\n",
    "\n",
    "#  output directory\n",
    "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "\n",
    "#  save confusion matrices\n",
    "plot_enhanced_confusion_matrix(true_main, pred_main, main_categories,\n",
    "                     \"Main Category\", \"confusion_matrices/main_category.png\")\n",
    "\n",
    "plot_enhanced_confusion_matrix(true_sub, pred_sub, sub_categories,\n",
    "                     \"Sub Category\", \"confusion_matrices/sub_category.png\")\n",
    "\n",
    "plot_enhanced_confusion_matrix(true_interv, pred_interv, interventions,\n",
    "                     \"Intervention\", \"confusion_matrices/intervention.png\")\n",
    "\n",
    "plot_enhanced_confusion_matrix(true_priority, pred_priority, [str(p) for p in priorities],\n",
    "                     \"Priority\", \"confusion_matrices/priority.png\", figsize=(10, 8))\n",
    "\n",
    "\n",
    "def print_compact_report(true, pred, classes, title):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CLASSIFICATION REPORT: {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get the classification report as a dictionary\n",
    "    report = classification_report(\n",
    "        true, pred, \n",
    "        labels=range(len(classes)),\n",
    "        target_names=classes,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Print only classes that appear in the test data or have predictions\n",
    "    present_classes = set(true) | set(pred)\n",
    "    \n",
    "    print(f\"Classes present in test data: {len(present_classes)}/{len(classes)}\")\n",
    "    print(\"\\nPerformance on present classes:\")\n",
    "    print(f\"{'Class':30} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Support':>10}\")\n",
    "    \n",
    "    for i in present_classes:\n",
    "        class_name = classes[i]\n",
    "        print(f\"{class_name:30} {report[class_name]['precision']:>10.3f} \"\n",
    "              f\"{report[class_name]['recall']:>10.3f} \"\n",
    "              f\"{report[class_name]['f1-score']:>10.3f} \"\n",
    "              f\"{report[class_name]['support']:>10.0f}\")\n",
    "    \n",
    "    print(f\"\\nOverall Accuracy: {report['accuracy']:.3f}\")\n",
    "    print(f\"Macro Avg F1: {report['macro avg']['f1-score']:.3f}\")\n",
    "    print(f\"Weighted Avg F1: {report['weighted avg']['f1-score']:.3f}\")\n",
    "\n",
    "# Print compact reports\n",
    "print_compact_report(true_main, pred_main, main_categories, \"Main Category\")\n",
    "print_compact_report(true_sub, pred_sub, sub_categories, \"Sub Category\")\n",
    "print_compact_report(true_interv, pred_interv, interventions, \"Intervention\")\n",
    "print_compact_report(true_priority, pred_priority, [str(p) for p in priorities], \"Priority\")\n",
    "\n",
    "\n",
    "\n",
    "# Additional analysis\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ADDITIONAL ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"Main categories in test data: {set([main_categories[i] for i in true_main])}\")\n",
    "print(f\"Main categories not in test data: {set(main_categories) - set([main_categories[i] for i in true_main])}\")\n",
    "\n",
    "# Calculate and display per-task accuracy\n",
    "tasks = [\n",
    "    (\"Main Category\", true_main, pred_main),\n",
    "    (\"Sub Category\", true_sub, pred_sub),\n",
    "    (\"Intervention\", true_interv, pred_interv),\n",
    "    (\"Priority\", true_priority, pred_priority)\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Task':20} {'Accuracy':>10} {'Correct/Total':>15}\")\n",
    "for name, true, pred in tasks:\n",
    "    correct = sum(1 for t, p in zip(true, pred) if t == p)\n",
    "    accuracy = correct / len(true)\n",
    "    print(f\"{name:20} {accuracy:>10.2%} {f'{correct}/{len(true)}':>15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# {\n",
    "#     \"narrative\": \"On 15 November 2022, the helpline received a call from Salum Mwinyi, 17, in Korogwe District, Tanga Region. He wanted to understand why drug use among youth is harmful. The counselor explained the physical, social, and legal risks involved with abusing drugs, both legal drugs and illegal drugs. The counselor explained in detail about what each of the effects of the drugs and advised Salum not to get herself involveed with any drugs. Salum expressed appreciation for the advice.\",\n",
    "#     \"main_category\": \"Information\",\n",
    "#     \"sub_category\": \"Drug/Alcohol Abuse\",\n",
    "#     \"intervention\": \"Counselling\",\n",
    "#     \"priority\": 2\n",
    "# },\n",
    "{\n",
    "    \"narrative\": \"On 16 November 2022, the helpline was contacted by Jafari Said, 25, from Kilombero District, Morogoro Region. He asked how to provide a safe home environment for his two young sisters. The counselor advised him on good parenting practices and protecting them from abuse.\",\n",
    "    \"main_category\": \"Advice and Counselling\",\n",
    "    \"sub_category\": \"Relationships (Parent/Child)\",\n",
    "    \"intervention\": \"Counselling\",\n",
    "    \"priority\": 2\n",
    "},\n",
    "# narrative =  \"On 15 November 2022, the helpline received a call from Salum Mwinyi, 17, in Korogwe District, Tanga Region. He wanted to understand why drug use among youth is harmful. The counselor explained the physical, social, and legal risks involved with abusing drugs, both legal drugs and illegal drugs. The counselor explained in detail about what each of the effects of the drugs and advised Salum not to get herself involveed with any drugs. Salum expressed appreciation for the advice.\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Main Category: Advice and Counselling\n",
      "Predicted Sub Category: Self Esteem\n",
      "Predicted Intervention: Counselling\n",
      "Predicted Priority: 2\n"
     ]
    }
   ],
   "source": [
    "# narrative=\" On <DATE_TIME> a girl <PERSON> (<DATE_TIME> ) from <LOCATION> district, <LOCATION> region called on 116 to report of the injustices done to her by a person who was to take care of her wellbeing. She reported that her stepfather raped her and abused her sexually and she was 2 months pregnant and is forced to abort as the stepfather threatened her that He will kill her if she does not abort. She reported that she was not the only one who was abused by the stepfather but her mother was also abused by the stepfather. \"\n",
    "narrative= \"On 16 November 2022, the helpline was contacted by Jafari Said, 25, from Kilombero District, Morogoro Region. He asked how to provide a safe home environment for his two young sisters. The counselor advised him on good parenting practices and protecting them from abuse.\",\n",
    "\n",
    "main_idx, sub_idx, interv_idx, priority_idx = classify_multitask_case_return_indices(\n",
    "    narrative[0]\n",
    ")\n",
    "pred_main.append(main_idx)\n",
    "pred_sub.append(sub_idx)\n",
    "pred_interv.append(interv_idx)\n",
    "pred_priority.append(priority_idx)\n",
    "\n",
    "print(\"Predicted Main Category:\", main_categories[main_idx])\n",
    "print(\"Predicted Sub Category:\", sub_categories[sub_idx])\n",
    "print(\"Predicted Intervention:\", interventions[interv_idx])\n",
    "print(\"Predicted Priority:\", priorities[priority_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
