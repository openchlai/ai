# Base configuration for Whisper Swahili training
model:
  name: "openai/whisper-large-v2"
  language: "sw"
  task: "transcribe"
  use_peft: false
  peft_config:
    r: 32
    lora_alpha: 64
    target_modules: ["q_proj", "v_proj"]
    lora_dropout: 0.1

dataset:
  name: "mozilla-foundation/common_voice_17_0"
  language: "sw"  # Swahili language code
  train_samples: null  # null means use all
  test_samples: null
  num_workers: 4
  preprocessing_batch_size: 100

training:
  output_dir: "./whisper-large-v2-sw"
  max_steps: 5000
  learning_rate: 0.00001
  warmup_steps: 500
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  fp16: true
  evaluation_strategy: "steps"
  eval_steps: 500
  save_steps: 500
  logging_steps: 25
  load_best_model_at_end: true
  metric_for_best_model: "wer"
  greater_is_better: false
  push_to_hub: false
  hub_model_id: null  # Set if push_to_hub is true"
  dataloader_num_workers: 2
  save_total_limit: 3
  optim: "adamw_torch"

mlflow:
  tracking_uri: "http://localhost:5000"  # Your local MLflow
  experiment_name: "whisper-swahili-training"
  run_name: null  # Will be auto-generated if null
  tags:
    project: "OpenCHS"
    model_type: "whisper"
    dataset: "common_voice_17"
    language: "swahili"

logging:
  use_mlflow: true
  use_tensorboard: true
  use_wandb: false
  tensorboard_dir: "./logs/tensorboard"
  save_tensorboard_to_hf: true