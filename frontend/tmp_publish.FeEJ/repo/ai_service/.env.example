# Application Settings
APP_NAME=AI Pipeline
APP_VERSION=0.1.0
DEBUG=true
LOG_LEVEL=INFO

# Resource Management
MAX_CONCURRENT_GPU_REQUESTS=1
MAX_QUEUE_SIZE=20
REQUEST_TIMEOUT=300
QUEUE_MONITOR_INTERVAL=30

# Model Configuration
MODEL_CACHE_SIZE=8192
CLEANUP_INTERVAL=3600
ENABLE_MODEL_LOADING=false

# Security
SITE_ID=dev-site-001
DATA_RETENTION_HOURS=24

# Performance
ENABLE_QUEUE_METRICS=true
ALERT_QUEUE_SIZE=15
ALERT_MEMORY_USAGE=90

# Paths(Update these paths as needed)
MODELS_PATH=
LOGS_PATH=
TEMP_PATH=

# Redis
REDIS_URL=redis://localhost:6379/0
REDIS_TASK_DB=1

# Streaming Configuration
ENABLE_STREAMING=true
MAX_STREAMING_SLOTS=2
MAX_BATCH_SLOTS=1
STREAMING_PORT=8300
STREAMING_HOST=0.0.0.0

# Redis Streaming Configuration  
REDIS_STREAMING_DB=2
REDIS_STREAMING_CHANNEL_PREFIX=ai_streaming

# Performance Settings
WHISPER_STREAMING_MODEL=base  # Lighter model for real-time
WHISPER_BATCH_MODEL=large-v3  # Full model for batch processing

ASTERISK_SERVER_IP=your.ip.address